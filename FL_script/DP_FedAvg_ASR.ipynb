{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24869fa7-e79e-41bc-866e-24a1f2950bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differentially Private Federated ASR with DP-FedAvg (using f̃_c estimator)\n",
    "# Based on: McMahan et al., 2018 (ICLR) and user's ASR FedAvg setup\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from collections import defaultdict\n",
    "from opacus.accountants import RDPAccountant\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# --- Configurable Constants ---\n",
    "q = 0.05  # Sample rate\n",
    "S = 15.0  # Clipping norm\n",
    "Wmin = 20  # Minimum total weight in denominator\n",
    "rounds = 10\n",
    "noise_levels = [0.006, 0.012, 0.024]  # Lambda values (stddev for Gaussian noise)\n",
    "\n",
    "# --- Placeholder: Client Data Setup & Helper Functions ---\n",
    "# Assume: client_datasets and eval_dataset already loaded\n",
    "# Assume: global_model, processor, data_collator are initialized\n",
    "\n",
    "# --- Clipping function: Flat Clip (Eq. 1 from paper) ---\n",
    "def flat_clip(delta_k, S):\n",
    "    norm = torch.norm(delta_k)\n",
    "    if norm > S:\n",
    "        delta_k = delta_k * (S / norm)\n",
    "    return delta_k\n",
    "\n",
    "# --- DP-FedAvg update estimator (f̃_c) ---\n",
    "def dp_aggregate_f_c(updates, weights):\n",
    "    W = sum(weights)\n",
    "    denom = max(q * Wmin, W)\n",
    "    agg = sum([w * u for u, w in zip(updates, weights)]) / denom\n",
    "    return agg\n",
    "\n",
    "# --- Train loop with DP noise ---\n",
    "def train_dp_fedavg(global_model, noise_std, label):\n",
    "    model = copy.deepcopy(global_model)\n",
    "    accountant = RDPAccountant()\n",
    "    accs = []\n",
    "\n",
    "    for rnd in range(rounds):\n",
    "        selected = random.sample(client_datasets, int(q * len(client_datasets)))\n",
    "        updates = []\n",
    "        weights = []\n",
    "\n",
    "        for client_data in selected:\n",
    "            local_model = copy.deepcopy(model)\n",
    "            state_before = copy.deepcopy(local_model.state_dict())\n",
    "\n",
    "            state_after, _ = local_finetune(local_model, client_data, processor, data_collator, compute_metrics, \"tmp\")\n",
    "            delta = {k: state_after[k] - state_before[k] for k in state_before}\n",
    "            clipped_delta = {k: flat_clip(v, S) for k, v in delta.items()}\n",
    "            updates.append(clipped_delta)\n",
    "            weights.append(1.0)  # Assume equal weights for now\n",
    "\n",
    "        # Aggregate updates with noise\n",
    "        avg_update = dp_aggregate_f_c(updates, weights)\n",
    "        noise = {k: torch.normal(0, noise_std * S, size=v.size()).to(v.device) for k, v in avg_update.items()}\n",
    "        noisy_update = {k: avg_update[k] + noise[k] for k in avg_update}\n",
    "\n",
    "        new_state = model.state_dict()\n",
    "        for k in new_state:\n",
    "            new_state[k] += noisy_update[k]\n",
    "        model.load_state_dict(new_state)\n",
    "\n",
    "        # Evaluate\n",
    "        metrics = evaluate_global_model(model, eval_dataset)\n",
    "        accs.append(metrics['eval_wer'])\n",
    "        print(f\"Round {rnd + 1}, Noise: {noise_std}, WER: {metrics['eval_wer']:.3f}\")\n",
    "\n",
    "    return accs\n",
    "\n",
    "# --- Run DP FedAvg for Different Noise Settings ---\n",
    "results = {}\n",
    "for sigma in noise_levels:\n",
    "    acc_curve = train_dp_fedavg(global_model, sigma, label=f\"DP-{sigma}\")\n",
    "    results[f\"DP-sigma={sigma}\"] = acc_curve\n",
    "\n",
    "# --- Baseline (non-private) ---\n",
    "baseline_metrics = []\n",
    "global_model = copy.deepcopy(base_model)\n",
    "for round_num in range(rounds):\n",
    "    selected_clients = random.sample(client_datasets, k=5)\n",
    "    weights = []\n",
    "    for client_data in selected_clients:\n",
    "        local_model = copy.deepcopy(global_model)\n",
    "        delta, _ = local_finetune(local_model, client_data, processor, data_collator, compute_metrics, \"tmp\")\n",
    "        weights.append(delta)\n",
    "\n",
    "    avg_update = fed_avg(weights)\n",
    "    global_model.load_state_dict(avg_update)\n",
    "    metrics = evaluate_global_model(global_model, eval_dataset)\n",
    "    baseline_metrics.append(metrics['eval_wer'])\n",
    "    print(f\"Baseline Round {round_num + 1}, WER: {metrics['eval_wer']:.3f}\")\n",
    "\n",
    "results[\"Baseline\"] = baseline_metrics\n",
    "\n",
    "# --- Plotting Noise Scheduling & Baseline Comparison ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "for label, vals in results.items():\n",
    "    plt.plot(range(1, rounds + 1), vals, label=label)\n",
    "plt.xlabel(\"Communication Round\")\n",
    "plt.ylabel(\"WER\")\n",
    "plt.title(\"Noise Scheduling vs Baseline in DP-FedAvg\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"dp_fedavg_wer_comparison.png\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
