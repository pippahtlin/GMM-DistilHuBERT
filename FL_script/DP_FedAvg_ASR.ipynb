{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fa08e45-253d-40b9-9eec-7e31b11aa1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7d1eda3-2308-4845-bc2a-afc723acc6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "from datasets import load_from_disk\n",
    "from transformers import TrainingArguments, Trainer, AutoProcessor, AutoModelForCTC\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from collections import defaultdict\n",
    "from opacus.accountants import RDPAccountant\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import utils\n",
    "from utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(217)\n",
    "np.random.seed(217)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98370d45-61c1-487f-9957-e52bf8b61c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of HubertForCTC were not initialized from the model checkpoint at ntu-spml/distilhubert and are newly initialized: ['lm_head.bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"/scratch/pippalin2/jupyter/GMM-DistilHuBERT/processor\")\n",
    "base_model = AutoModelForCTC.from_pretrained(\"ntu-spml/distilhubert\").to(\"cuda\")\n",
    "utils.processor = processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8020c1ca-96d3-43be-a74f-89152ad80782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b95636bafe148e297b5c3a63fba193e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_from_disk(\"/scratch/pippalin2/jupyter/GMM-DistilHuBERT/processed_dataset\")\n",
    "dataset = dataset.train_test_split(test_size=0.1, seed=217)\n",
    "train_dataset = dataset[\"train\"]\n",
    "eval_dataset = dataset[\"test\"]\n",
    "client_datasets = split_into_clients_nonuniform(train_dataset, num_clients=20, min_frac=0.01, max_frac=0.1)\n",
    "\n",
    "data_collator = DataCollatorCTCWithPadding(processor)\n",
    "model_save_path = \"/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/DP_FedAvg_checkpoints\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9331293c-cab2-45c7-9024-e47e4185c9fc",
   "metadata": {},
   "source": [
    "#### Hyper-parameter value (z, S, Wmin):\n",
    "* empirically estimate the L2 norm of the model update produced by each client in one round, to choose a proper clipping bound S: keep most of the $\\Delta_k$ unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "851bde0e-911d-4bde-8488-2c7debefe64f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2278.628500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1144.216600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1103.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1052.447200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1015.152300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>984.246300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1055.685500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1074.428100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1033.252100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1081.136500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1000.500500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='486' max='486' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [486/486 01:23, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2200.529700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1093.260400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1051.110300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1067.975900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1065.988000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1089.944200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1032.003900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1032.986200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1072.169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1044.296700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1037.402000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1014.642400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1042.638500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1071.115100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1011.102300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>983.911400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1052.227300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1108.653500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1087.988600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1030.463000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1059.659600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1022.854000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>992.016300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1011.005600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>956.303600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>995.391000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1066.788300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>996.519400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>952.159900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1055.577300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1033.542200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1044.557000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>999.093600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1019.489000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>998.242400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>966.184000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>968.138200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>927.202100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>915.793800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>927.800800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>915.875400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>900.821900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>857.450100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>901.431000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>902.119000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>829.453400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>863.541500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>858.530000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='206' max='206' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [206/206 00:35, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2162.903900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1181.832700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1038.874400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1020.803100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1135.995300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1006.399300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1058.906300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1047.636700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1013.818200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1063.605100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>908.378000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1103.018200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1060.399900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1100.431700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1073.422000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1022.479800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>993.767100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1041.152700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1053.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1010.520000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2269.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1143.165500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1067.895600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1000.734100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1053.445400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1006.359800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1030.532300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1094.851600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1048.700600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1088.712900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>997.150100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1065.931600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1094.104800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1088.847500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1095.985900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1073.500400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1078.933000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>998.540300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1063.723700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1027.831200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1079.605300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1040.552100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1049.024400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1020.219800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1080.979000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1063.361500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1021.094600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1005.860700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1108.997300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1110.824700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1020.035800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1070.703600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1081.269700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1005.599700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>995.771500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1028.003400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>974.871600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1018.257400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='346' max='346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [346/346 00:59, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2243.712700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1151.095400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1115.544200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1082.879200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1011.391800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1062.577900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1117.969200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1044.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1093.452800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1109.414700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1016.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1031.788000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1087.293400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1103.163800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1064.887300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1098.529500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1041.046300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1046.304700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1041.526200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1073.843800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1039.458300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1061.437400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1027.298800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1086.215300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1067.792600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1082.989000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1082.285500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1104.151100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1058.299000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1015.548300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1074.462800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1094.639600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1031.776900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1024.369500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='404' max='404' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [404/404 01:09, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2278.649400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1170.219700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1087.812700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1048.041600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1086.171100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1055.977000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1044.291900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1107.385800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1062.055900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1079.121200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1025.634600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1023.113300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1040.176000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1086.432500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1052.697300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1074.258300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1075.112300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1105.932200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1083.168800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1104.268400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>975.617400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1051.565200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1083.384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1106.504300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1098.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1067.455800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1082.012900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>983.756100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1025.819900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1072.107200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>961.903700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1045.940700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1041.340600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1045.556200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1030.402500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>996.753600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>999.642400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>983.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1000.351600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1014.275600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='314' max='314' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [314/314 00:54, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2243.164100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1130.101600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1032.673500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1028.298300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1057.129100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1080.059300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1046.166600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1019.729600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1094.730600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1024.452300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1076.152700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>996.161200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1002.567900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1045.070900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1078.337400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1029.701700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1063.554900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1036.442000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1061.858200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1077.682400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1089.166100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>985.233400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1014.924300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1102.287900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>997.083400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1013.032700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>993.774800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1032.731300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1037.232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1056.976700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1104.005200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2247.578700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1170.044300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1056.201800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1073.385800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1052.497800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1057.321300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1042.739100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1032.578500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1010.634400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1063.981900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1192.612600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1049.962100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1021.431700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1082.332200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1102.342100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1059.428800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1138.265100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1070.506300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1053.661300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1010.615400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1066.963700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1039.886600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1131.674300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1094.655300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1018.467200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1043.917200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1017.906200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1078.532800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1047.033800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1144.041500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>969.227900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1129.857900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1062.360700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1105.955300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1069.542800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1061.825500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1026.479100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1013.389900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2301.520500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1160.449900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1115.129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1057.689800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1058.807700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1015.838400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1006.851900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1023.458500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1105.488500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1055.515100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1014.810900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1068.813900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1047.306300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1017.356800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1021.557500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1078.954900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1083.172600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1101.049200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1040.179400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1002.803700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1076.601300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='262' max='262' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [262/262 00:45, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2193.985200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1153.740300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1077.585100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1078.425500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1111.205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>993.356500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1083.943300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1056.496000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1033.819200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1112.727900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1061.064000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1019.967400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1022.235100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1054.100400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1024.245100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1101.508300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1136.691000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1025.809500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>998.801100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1050.477300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1013.997700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1081.073400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1052.262000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1059.285100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1088.375200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1017.351800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 00:54, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2175.849200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1138.301500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1097.893700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1061.574700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1084.043800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>996.927000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1059.913100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1006.405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1038.862600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1077.247200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1071.332400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1027.799400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1075.049800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1171.954700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1098.313000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1082.243400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1024.934500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1061.623800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1131.953600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1085.335800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1046.946000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1035.030800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1033.134400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1007.142900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1113.838400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1088.705500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1062.915400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1067.392200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>964.682500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1073.844800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1066.948400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='416' max='416' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [416/416 01:11, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2288.603500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1191.091500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1008.528400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1012.231500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1085.927500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1097.183000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1079.750400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1118.184000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1083.171300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1027.008500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1083.359700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>952.930800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>984.568500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1037.155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1057.166100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1072.635400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1095.263300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1077.342000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1101.554600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1064.182500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1023.078000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1073.536900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1078.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>980.561600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1063.914700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1038.218200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1040.280500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1114.427400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1117.054200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1109.231300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1125.633600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1043.905900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1026.990100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1043.479500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>984.724700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>988.895000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>982.251900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>994.589700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1051.805800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1029.562700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1027.188000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='466' max='466' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [466/466 01:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2220.301400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1092.071400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1098.159800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1105.086700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1082.195700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1086.683800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1063.656000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1058.314800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>982.816800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1020.080500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1140.594300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1034.024900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1049.370800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1021.865900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1043.137700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1054.610700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1072.836900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1074.188500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1081.379100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>973.719500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1048.576100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>979.464700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1053.660100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1007.380500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1037.356200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1043.081500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1056.248000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1033.686800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1045.278500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1055.454700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1047.188000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1006.519700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>894.269700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>993.402300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>885.629900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>936.751900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>954.584100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>885.730900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>883.270300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>898.307400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>918.800800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>911.611300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>856.923300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>904.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>890.369300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>892.715400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='396' max='396' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [396/396 01:08, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2304.746900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1130.939300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1132.094700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1013.416900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1115.391500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1099.364200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1051.377000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1057.496500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1045.464700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>999.423800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1044.860700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1067.888700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1073.555000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1030.884000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1016.627300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1027.752400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1010.469700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1094.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1029.920500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>938.543400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1089.825200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1043.395700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1079.774800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1000.914500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1055.471400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1092.516000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1061.367600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1039.827200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1076.439600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1021.696800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1021.191700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1011.675700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1038.183000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1041.481200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1008.787900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1040.170800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1018.423300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>936.527200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>990.776300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='280' max='280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [280/280 00:48, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2226.326600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1041.852000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1074.542000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1087.725700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1118.395500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1045.595600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1104.390300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1066.885900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1090.555600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1114.936300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1099.881600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1056.961600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1057.055300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1048.538900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1045.552800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1052.406700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1101.414100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1134.902400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1050.923000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1089.293200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1046.186400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1106.647400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1071.863600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1008.444400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1071.510300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1048.941800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1076.479200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1018.235900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='486' max='486' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [486/486 01:23, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2359.310500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1114.669900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1112.593800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1112.072900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1143.227500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1114.233600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1080.398700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>997.430200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1083.573500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>996.129600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1078.457400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1100.834700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1060.061000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1067.880200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1114.042600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>964.838400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1035.206500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1054.736300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1029.277000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1099.684500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1089.792600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1051.495300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1055.822100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1047.200900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1029.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1062.319000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1024.256200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1002.026800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1093.403500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1094.891900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1105.381200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1039.847900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1013.076500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1001.523700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1055.677700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>985.716200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1007.435000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1025.013700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>878.633100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>982.416700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1004.503900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>913.187100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>914.936300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>909.852200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>911.794500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>913.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>926.161900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>915.044500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2229.391000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1091.852000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1141.314300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1044.908400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1009.023700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1116.279900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>952.585100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>955.172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1124.577500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>985.365300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1073.697700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1037.363300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1050.694900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>991.412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1044.417300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1106.676200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1032.989800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1013.239600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>976.719600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1041.323500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='124' max='124' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [124/124 00:21, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2326.129100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1123.403500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1158.883700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1015.120700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1074.834000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1016.970500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1014.769000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1070.293400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1076.498900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1099.438100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1075.054800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1069.598600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='444' max='444' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [444/444 01:16, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2105.951800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1212.677100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1084.397900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1086.717600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1009.224900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1107.418600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1065.526100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1028.965800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1043.594800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1053.422900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1061.369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1143.129600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1050.972700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1034.468200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1069.781200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1092.886400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1107.543700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1086.327200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1088.460400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1047.735300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1088.289600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1030.747800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1019.106400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1049.380300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>963.687700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1117.727300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1085.950600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1102.509500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1059.587700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1052.040500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1071.501300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1038.799000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1014.194100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1067.841700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1065.224300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1094.549900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1038.738200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1051.352200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1030.742700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1020.548900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>956.314500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1026.246500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>973.821200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1041.660300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='184' max='184' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [184/184 00:31, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2173.363900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1112.219900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1093.858400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1079.545700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1103.813600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1047.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1027.605700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>996.229700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1105.117200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1111.891600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1032.996500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1007.636900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1047.499600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1053.697600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1076.029900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1008.649800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1089.215200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1095.914100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "norms = []\n",
    "\n",
    "for client_data in client_datasets:  # All 20 clients\n",
    "    local_model = copy.deepcopy(base_model)\n",
    "    before = copy.deepcopy(local_model.state_dict())\n",
    "\n",
    "    after, _ = local_finetune(local_model, client_data, processor, data_collator, compute_metrics, model_save_path)\n",
    "    delta = {k: after[k] - before[k] for k in before}\n",
    "    flat = torch.cat([v.flatten() for v in delta.values()])\n",
    "    norms.append(torch.norm(flat).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6b6d3d7-3911-4f20-bd68-fabd03ba2053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min norm: 5.980891704559326\n",
      "Median norm: 7.082739353179932\n",
      "90th percentile: 9.8637451171875\n",
      "Max norm: 10.399197578430176\n"
     ]
    }
   ],
   "source": [
    "plt.hist(norms, bins=10)\n",
    "plt.title(\"Per-Client Update Norms (All 20 Clients)\")\n",
    "plt.xlabel(\"L2 Norm of k\")\n",
    "plt.ylabel(\"Client Count\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"Min norm:\", np.min(norms))\n",
    "print(\"Median norm:\", np.median(norms))\n",
    "print(\"90th percentile:\", np.percentile(norms, 90))\n",
    "print(\"Max norm:\", np.max(norms))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fba40a-0f20-44f2-b97d-266938bdda83",
   "metadata": {},
   "source": [
    "So we set $S = [7, 9, 11]$, corresponding to median (tight clip), 75%, and optimal clip (avoids outlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b12c1f5-fe12-4e24-8117-1ac8bfa11525",
   "metadata": {},
   "source": [
    "* $W_{min} = q \\cdot K $, K = total number of users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ea6fb8-0a6d-49f0-9259-d246eec6ebc2",
   "metadata": {},
   "source": [
    "* $z = 0.005$: balance privacy protection with the models ability to learn in our small-scale DP-FedAvg setup with only 20 clients. This value is significantly lower than the $z = 1.0$ used in large-scale experiments (e.g., with over 700,000 users), and is scaled down to reflect our much smaller population size.\n",
    "\n",
    "Theoretical results and empirical evidence suggest that privacy loss per round grows approximately as:\n",
    "\n",
    "$$\n",
    "\\epsilon \\sim \\frac{q^2 z^2 T}{K}\n",
    "$$\n",
    "\n",
    "Because $K$ is small in our case, keeping $z$ low is essential to avoid rapid accumulation of privacy loss. At the same time, setting $z = 0.05$ leads to moderate noise levels (e.g., $\\sigma = 0.05 \\ \\text{to} \\ 0.1$ for typical clipping norms), which are comparable to the magnitude of per-client updates. This allows us to observe the tradeoff between clipping and noise without completely degrading model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cd3d98-4871-49f2-ba3c-9cfe9b3d947c",
   "metadata": {},
   "source": [
    "The approximation that privacy loss scales with $q^2z^2T$originates from the analysis in:\n",
    "Abadi, M., Chu, A., Goodfellow, I., McMahan, H. B., Mironov, I., Talwar, K., & Zhang, L. (2016).\n",
    "Deep learning with differential privacy.\n",
    "In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security (pp. 308318).\n",
    "https://arxiv.org/abs/1607.00133 \\\n",
    "Specifically, Appendix A of the paper provides the detailed analysis of the Moments Accountant, and Figures 2 and 3 show empirically that privacy loss grows roughly linearly with T, and quadratically with q and z, validating the simplified scaling rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed2a2a4d-b09e-446c-90ae-56c361581a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 0.25  # Sample rate\n",
    "z = 0.005\n",
    "S_vals = [7, 9, 11]  # Clipping norm\n",
    "Wmin = 5\n",
    "rounds = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea18c15b-b926-413d-a02f-0dfdc95fb471",
   "metadata": {},
   "source": [
    "#### Run DP FedAvg for Different Noise Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e85394a-396e-4b17-b09b-c8d363c7ef8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[S_7_z_0.005] Using S=7, z=0.005, sigma=0.0560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='262' max='262' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [262/262 00:44, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2193.986100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1153.740800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1077.585200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1078.425600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1111.205100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>993.356500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1083.943100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1056.496300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1033.819500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1112.728300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1061.064000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1019.967400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1022.235100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1054.100600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1024.245100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1101.507900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1136.690300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1025.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>998.801600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1050.476900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1013.997500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1081.073200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1052.261800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1059.285000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1088.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1017.351700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2247.580300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1170.044500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1056.201600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1073.385700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1052.497800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1057.321700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1042.739400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1032.578500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1010.633900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1063.981100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1192.613900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1049.963200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1021.431200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1082.329700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1102.346000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1059.431100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1138.254500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1070.501800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1053.649400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1010.611000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1066.974700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1039.915400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1131.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1094.664300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1018.471600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1043.916700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1017.907900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1078.536300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1047.036100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1144.049000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>969.237800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1129.872100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1062.379000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1105.976700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1069.568000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1061.852600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1026.503900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1013.414800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='404' max='404' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [404/404 01:09, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2278.649200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1170.219400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1087.812900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1048.041800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1086.171400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1055.977000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1044.291800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1107.385900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1062.056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1079.121000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1025.634000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1023.118500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1040.179300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1086.409800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1052.702500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1074.280100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1075.110400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1105.928000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1083.170100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1104.266000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>975.619000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1051.560300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1083.385200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1106.499300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1098.956200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1067.481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1082.022800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>983.809200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1025.932300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1072.306100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>962.159900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1046.258000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1041.701900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1045.952300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1030.805100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>997.162900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1000.045400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>983.393300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1000.735400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1014.678900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2301.516600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1160.447900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1115.129500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1057.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1058.807700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1015.838200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1006.851800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1023.458200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1105.488200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1055.515800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1014.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1068.813800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1047.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1017.358500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1021.555400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1078.953900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1083.174100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1101.048300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1040.178500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1002.802700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1076.600200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='444' max='444' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [444/444 01:16, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2105.951800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1212.677100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1084.397900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1086.717800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1009.224800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1107.418800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1065.526200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1028.965700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1043.593800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1053.422900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1061.369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1143.130700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1050.973300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1034.470300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1069.792800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1092.947600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1107.537000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1086.035700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1088.619500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1047.727100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1088.327200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1030.746100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1019.049400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1049.403500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>963.864300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1118.044900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1086.012800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1102.339600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1059.921200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1052.156200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1071.803600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1038.983400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1015.940100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1070.726400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1069.298100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1098.548900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1043.697200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1056.597900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1036.891000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1026.788100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>963.189000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1033.933500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>981.659300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1050.195100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=1.0000, CER=0.9803, SER=1.0000\n",
      "Round 1, =0.0560, =22096.5290, WER=1.000, Loss=1095.4672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1229.061700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1075.618600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1048.113600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>993.685600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1047.854700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1001.057100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1028.507500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1092.482300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1046.480400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1087.006600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>996.977300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1066.704900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1089.612800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1088.914000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1093.231500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1073.343200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1079.403100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>999.468400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1063.436700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1029.333700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1081.125500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1043.423500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1050.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1021.626500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1082.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1066.273100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1023.629200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1009.118400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1113.135300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1116.431100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1027.124900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1076.588600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1091.253100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1017.332100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1009.666900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1043.015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>991.313500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1036.688000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1257.038000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1072.327300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1081.580900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1041.300200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1008.228900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>979.434800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1048.882500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1068.520100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1026.667200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1076.656300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>994.760700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1244.585700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1083.479400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1095.406200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1049.924400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1053.509800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1013.282900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1008.733400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1023.608200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1105.619700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1059.912200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1016.612000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1070.359600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1043.670500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1017.424200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1021.529900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1078.298400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1083.726300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1101.532500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1040.822100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1002.793500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1076.506100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1256.362900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1101.084600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1035.115600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1063.333300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1048.996400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1052.976900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1043.283400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1031.570400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1013.231100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1061.481600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1189.593200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1048.966000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1022.400700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1081.126000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1102.672500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1059.315600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1135.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1071.260600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1054.358500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1010.559700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1067.326900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1043.377300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1132.683500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1095.491400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1018.442700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1044.611300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1019.537800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1080.472000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1048.961400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1147.611300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>973.238000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1134.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1068.426700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1114.901400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1080.305700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1074.537900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1039.790200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1025.940400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1243.320500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1035.759500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1123.291600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1036.218300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1006.939500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1113.351400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>948.683800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>951.798500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1122.053300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>981.299400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1072.303100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1038.666800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1049.382300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>989.028700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1041.584300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1104.844700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1032.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1011.697900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>975.364200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1040.891300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=1.0637, CER=0.9595, SER=1.0000\n",
      "Round 2, =0.0560, =44081.2798, WER=1.064, Loss=1056.9719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1322.377600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1074.128300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1049.375200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>992.871900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1049.893100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1004.522300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1032.372300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1091.905300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1049.384900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1089.131500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>999.005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1068.822800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1087.869100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1087.507200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1094.276100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1072.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1079.592100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>998.811500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1065.095200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1028.635500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1082.306200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1047.124200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1053.016900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1023.334800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1084.309700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1067.061100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1024.840800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1009.362400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1114.224800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1117.412500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1027.084000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1077.978600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1091.909400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1017.327700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1009.831000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1043.877200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>992.561700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1037.616800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1371.372200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1083.061600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1082.522400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1042.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1009.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>980.423800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1049.995900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1069.362100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1027.359900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1077.211900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>995.024600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1313.080900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1085.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1095.699000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1050.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1052.919100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1011.259300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1005.176200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1022.331300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1103.644300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1055.457600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1014.043100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1067.651300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1041.971800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1016.257400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1021.810100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1078.892300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1083.016500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1102.290600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1042.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1003.906200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1076.968000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1335.248100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1098.207900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1036.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1062.641400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1046.780400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1053.465500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1044.515900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1035.811400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1011.111700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1064.344500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1193.468200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1053.979700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1022.297700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1084.048200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1102.352000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1059.594200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1139.667600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1072.791400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1055.271900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1011.521000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1068.036200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1041.403800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1132.966600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1096.153300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1019.931800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1045.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1019.758900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1081.740500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1050.523300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1150.462500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>974.514300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1135.290500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1070.027500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1115.834800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1081.667400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1075.488900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1040.699800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1026.885400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1331.855400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1038.781500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1123.941800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1036.449600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1005.558900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1115.206200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>950.801600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>952.870300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1122.391400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>982.107800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1072.605600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1036.082500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1048.961700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>990.559900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1042.278700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1105.811600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1032.623700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1012.444700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>976.075400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1041.149500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=1.0000, CER=0.9897, SER=1.0000\n",
      "Round 3, =0.0560, =66066.0305, WER=1.000, Loss=1062.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1257.816900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1081.164500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1056.468800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>998.367200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1057.460600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1009.059000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1034.859500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1095.268000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1051.974600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1092.068900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1001.996400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1069.738500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1099.308100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1090.284800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1096.808400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1077.777300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1082.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1002.915900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1067.308400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1031.441600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1082.784600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1045.573400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1052.616900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1024.332200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1085.394600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1069.553400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1026.759700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1011.287600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1116.202500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1120.317500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1030.909600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1080.846900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1094.222700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1019.770100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1013.345700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1045.916600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>994.835700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1039.620900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1296.505600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1102.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1088.411300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1048.579600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1015.304100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>982.762700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1053.531700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1072.723300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1030.888400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1081.370900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>998.909600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1266.930600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1097.287800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1104.609200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1060.394500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1058.781100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1015.724900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1011.446100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1027.059500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1106.788800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1057.568800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1017.892800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1070.554600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1045.140100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1019.085300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1023.401600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1080.843000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1087.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1103.973700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1043.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1005.411700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1080.105800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1290.284800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1110.190500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1041.431700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1067.930600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1051.487300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1057.269700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1048.593700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1046.368800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1015.431200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1070.036900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1198.584600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1061.009400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1027.217100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1089.565600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1104.488700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1061.902100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1143.319200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1074.305200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1057.078100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1013.637800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1070.431500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1045.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1135.984200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1099.296100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1022.430800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1048.407900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1022.684500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1083.940600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1052.184000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1152.189300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>975.942000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1137.353300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1071.114200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1118.442600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1083.084000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1078.069300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1042.616600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1028.577100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1284.931800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1042.484600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1122.827300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1041.185400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1015.378900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1116.415000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>953.212900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>954.319900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1125.818200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>983.306200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1078.016400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1040.972700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1051.611600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>993.008500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1044.814100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1110.093200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1034.189600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1014.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>977.787600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1043.518900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=1.0000, CER=1.0000, SER=1.0000\n",
      "Round 4, =0.0560, =88050.7813, WER=1.000, Loss=1062.9526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1197.173700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1107.534600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1072.875900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1015.356900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1072.046600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1018.759600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1047.670300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1109.661500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1064.885400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1101.950100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1007.576500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1077.933000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1098.978900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1097.488800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1106.400600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1082.441600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1088.557800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1009.573500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1073.409200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1038.422800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1089.834500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1052.732200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1058.380400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1030.990900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1092.725200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1075.354400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1032.709600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1016.066500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1124.460800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1123.845100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1035.668800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1088.122300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1101.385700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1024.762900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1018.733000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1050.924900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>998.813000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1045.027800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1219.428500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1108.943800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1114.569700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1064.473600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1027.065100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>998.301300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1066.667300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1080.387100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1042.998800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1089.089500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1007.133100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1219.434500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1120.356800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1122.096300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1073.946600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1076.580600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1031.826400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1023.801800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1039.324500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1116.567200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1070.230100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1024.687700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1081.295700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1057.391800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1029.499800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1031.464400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1089.143600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1093.213200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1114.541700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1051.606400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1013.048500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1087.012800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1232.787400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1147.371700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1066.298700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1087.477400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1078.745900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1070.746200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1057.317800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1053.992400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1027.668800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1078.332400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1205.249000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1059.805500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1033.016900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1095.117000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1112.633700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1068.348300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1149.122700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1081.357400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1063.307100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1020.286400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1080.502500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1050.313900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1143.107600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1104.331500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1027.755500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1054.112900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1028.196000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1090.796500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1058.474500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1159.390400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>980.871700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1142.721800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1076.777800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1124.424800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1091.141000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1082.171800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1048.922000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1033.048500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1205.725900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1057.431600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1164.642000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1065.609700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1028.589600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1129.233000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>961.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>965.549300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1133.391100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>990.462500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1081.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1047.443400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1057.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1000.850200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1054.734600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1117.835500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1041.982000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1021.066000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>985.743000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1051.305800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=1.0000, CER=1.0000, SER=1.0000\n",
      "Round 5, =0.0560, =110035.5321, WER=1.000, Loss=1069.5880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1304.206200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1171.664600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1118.624900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1044.373000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1092.617700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1042.106300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1068.196600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1127.264200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1081.268800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1123.799900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1029.532300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1096.569500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1117.499700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1117.857700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1119.264100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1096.058400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1104.360700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1024.365000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1086.108200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1053.884300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1103.307300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1065.379300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1072.920200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1043.431600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1104.111800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1088.729300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1048.008100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1027.165600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1134.771200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1137.384400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1045.154500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1096.825100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1114.125100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1037.410400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1027.891700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1063.095300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1008.331600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1055.008100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1246.640800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1132.265600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1143.639600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1103.557100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1066.091200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1020.565300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1098.484500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1110.532500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1066.843700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1111.224200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1033.121300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1278.608400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1151.069700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1149.530200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1100.204400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1097.141900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1048.664500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1036.449900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1057.827300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1136.093600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1087.526500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1045.780500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1101.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1079.558300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1047.519100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1046.604100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1107.012300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1108.988900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1129.159600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1070.104300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1029.373600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1101.537500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1291.973600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1175.611500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1089.643600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1110.814900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1096.233700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1093.382300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1073.352500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1062.052800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1038.656700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1089.313600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1222.486000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1077.638600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1045.809400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1107.406600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1125.814500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1081.346500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1161.090800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1094.611100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1074.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1030.024500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1092.540500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1060.809900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1158.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1115.824600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1038.980100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1064.596700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1039.349100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1101.373800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1067.199100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1168.631800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>989.328400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1154.121500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1089.868400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1134.336300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1100.957400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1091.544500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1058.413300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1042.227100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1241.793700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1085.909900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1177.591200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1080.434600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1047.454100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1155.993000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>980.950600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>992.162400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1154.156200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1010.724900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1100.884800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1064.180400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1073.923300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1015.962100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1069.791100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1134.612200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1058.566700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1034.736000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1002.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1066.644900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=1.0000, CER=1.0000, SER=1.0000\n",
      "Round 6, =0.0560, =132020.2828, WER=1.000, Loss=1090.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1270.098500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1233.971600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1151.070100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1087.651000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1128.853600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1080.718000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1108.494900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1168.521900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1116.487100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1158.566700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1057.500200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1127.555100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1148.781800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1143.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1149.664500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1120.721300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1127.954600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1045.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1109.885600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1075.457500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1130.490800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1095.380300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1097.052900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1064.981800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1125.942800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1107.621700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1067.081200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1046.261300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1155.777400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1158.689600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1066.094500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1117.385400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1133.376700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1054.812000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1045.843000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1083.732400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1024.064600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1076.896700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1263.942800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1169.070300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1174.470100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1130.524000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1084.777000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1050.684200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1126.481800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1139.867800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1094.125800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1144.326000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1063.782600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1288.717800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1193.570100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1188.085600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1136.796900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1124.173800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1078.121800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1068.993300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1090.326100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1173.020900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1122.028000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1072.453800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1125.794600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1098.821900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1071.386400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1070.951800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1128.098700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1135.558600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1156.140900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1093.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1054.795700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1123.974600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1300.955200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1203.813000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1122.665300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1143.606700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1125.270800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1124.928600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1108.525200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1092.214900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1065.819300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1123.956400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1252.161700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1107.531300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1071.611500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1132.051600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1149.120500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1104.125100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1187.800600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1113.652300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1096.085700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1051.764600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1111.761900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1078.972200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1179.032400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1135.418800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1055.926500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1082.461300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1057.564000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1118.570800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1086.599800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1190.389100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1006.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1173.727900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1110.324000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1155.860200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1117.602600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1109.087300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1076.222600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1058.948400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1272.302200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1138.746500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1224.064300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1120.662600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1081.268200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1195.885200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1012.546700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1021.154000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1187.776300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1044.478700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1137.561400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1093.642900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1106.384400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1044.226900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1098.426000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1166.997700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1087.339500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1061.355000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1026.609700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1090.266100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=1.0000, CER=1.0000, SER=1.0000\n",
      "Round 7, =0.0560, =154005.0336, WER=1.000, Loss=1117.4053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1274.158600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1224.181100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1177.034800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1113.083000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1168.072000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1117.842100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1135.908700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1198.236500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1152.205500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1191.440900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1087.375600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1165.069700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1180.434600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1178.930900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1179.417500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1152.718800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1161.699800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1075.298400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1139.160700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1102.293000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1159.669300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1122.550200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1124.006300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1093.936500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1154.183000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1136.320900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1095.311300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1073.374800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1185.711600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1187.804800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1092.356100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1144.967700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1159.743500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1082.558900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1069.335900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1108.617700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1051.952700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1100.577100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1287.815600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1212.636900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1216.473700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1167.998800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1129.264800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1093.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1168.472500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1183.039900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1136.061500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1187.379500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1103.023200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1315.268800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1231.368800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1229.274200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1177.521100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1174.774500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1121.135500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1112.429500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1117.101900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1211.339100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1161.826400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1105.283200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1158.729400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1135.197000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1102.474900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1108.859100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1163.808500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1171.052900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1196.831200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1126.102100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1085.968500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1159.945600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1333.395100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1245.119100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1165.562700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1192.733200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1178.483400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1175.075200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1149.101800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1127.307800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1101.661100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1167.536200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1299.486900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1143.733500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1110.049800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1172.974900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1187.431900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1140.733200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1224.869800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1146.899400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1129.728500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1078.403900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1143.281200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1110.290200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1214.780600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1167.019500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1087.232300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1110.114600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1088.008600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1147.622600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1117.556500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1217.107200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1030.409800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1208.823500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1136.624900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1186.095300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1146.393000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1137.512700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1101.750600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1088.331200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1301.783300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1164.758600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1253.850100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1163.175300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1118.763900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1236.050700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1047.339100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1050.043000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1230.026700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1076.382400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1169.148700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1130.579200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1138.474300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1074.066800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1134.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1202.406100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1120.900800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1090.815900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1056.115700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1124.208600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=1.0000, CER=1.0000, SER=1.0000\n",
      "Round 8, =0.0560, =175989.7844, WER=1.000, Loss=1152.0275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1323.978000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1278.902300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1231.684100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1162.677300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1214.659200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1168.207900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1182.244600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1250.975200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1195.748500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1246.711800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1131.054500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1215.853700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1230.039200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1218.881600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1225.843100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1198.942300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1207.083100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1118.171900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1186.439200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1143.234600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1207.362700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1158.874500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1165.477000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1127.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1194.682200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1175.943300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1126.792200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1105.536000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1222.230500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1224.265700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1127.570400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1182.478800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1197.777700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1117.824100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1102.108400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1144.139300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1083.314900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1135.892200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1337.872300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1270.943400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1267.222300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1218.587600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1175.703400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1135.899500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1216.708100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1227.260800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1186.169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1236.691300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1144.448200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1356.504300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1292.347100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1289.248600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1231.576200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1239.452200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1178.654100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1161.496600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1178.610800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1260.288400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1208.511500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1155.350200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1216.910200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1190.571300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1151.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1154.824400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1214.477200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1223.270500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1245.095100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1171.291500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1135.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1206.596700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1357.177800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1292.229500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1218.214100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1244.610700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1233.383900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1225.611400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1193.187800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1175.116400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1152.219900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1208.678800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1348.012800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1188.882100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1154.539300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1222.534200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1237.493900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1185.939600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1265.904000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1195.823200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1166.684100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1120.331800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1185.431700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1148.611600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1258.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1206.918900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1122.809000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1147.429200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1125.728100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1181.525300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1154.715100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1257.941800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1060.629600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1249.206300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1173.739800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1221.710800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1180.838000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1171.690300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1136.777800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1121.860500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1342.030100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1216.447800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1316.489400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1210.994100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1162.526400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1289.639800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1096.633800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1092.467000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1278.443300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1120.721400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1219.347000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1175.249000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1184.899600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1121.702900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1175.581400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1251.178400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1162.057700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1134.603400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1099.339600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1171.966400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=1.0000, CER=1.0000, SER=1.0000\n",
      "Round 9, =0.0560, =197974.5351, WER=1.000, Loss=1198.2104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1378.850300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1338.120700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1301.858700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1220.158400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1279.185300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1224.165500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1249.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1307.745100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1255.744700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1302.168200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1184.986000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1268.941100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1284.861300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1275.390600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1281.716600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1252.784400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1263.387800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1164.722500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1233.990200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1187.903300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1257.752300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1210.667900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1217.142100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1175.719700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1244.504300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1226.816800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1174.590400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1149.900600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1269.033400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1275.167600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1168.647400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1230.097900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1241.727000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1160.362400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1148.304900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1188.036300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1121.115000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1178.993400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1390.314400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1326.207600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1330.311800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1281.030100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1231.873900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1188.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1277.652300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1290.348600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1246.527500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1299.002100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1204.631100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1427.978100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1359.940300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1358.118500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1289.685100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1286.684200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1230.125300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1217.805900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1233.194900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1323.265900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1263.891000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1211.566100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1271.864300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1241.069200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1207.257400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1205.504300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1271.911700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1280.766800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1306.920100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1228.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1184.220100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1262.064000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1422.348100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1362.297600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1272.526500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1294.874100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1277.811300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1276.352900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1243.985900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1226.349600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1197.844600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1264.621600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1408.033900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1237.807800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1203.767800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1271.683300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1284.318400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1231.799000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1316.621200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1233.021200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1212.221500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1165.851200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1243.516500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1194.471800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1310.100400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1254.693600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1165.792600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1187.203600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1164.122300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1221.587300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1190.733400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1301.664600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1099.539000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1294.865200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1219.289600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1269.269300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1222.365800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1212.867100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1178.217000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1162.895500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1399.856300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1273.008400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1373.339200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1274.528200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1228.571400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1363.176700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1145.804200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1160.178700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1338.158100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1182.142000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1273.773000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1234.019900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1242.906200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1177.207200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1236.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1309.718000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1213.171300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1190.252200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1150.339600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1227.302700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=1.0000, CER=1.0000, SER=1.0000\n",
      "Round 10, =0.0560, =219959.2859, WER=1.000, Loss=1252.8304\n",
      "[S_9_z_0.005] Using S=9, z=0.005, sigma=0.0720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2269.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1143.165800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1067.895000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1000.734100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1053.445500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1006.359600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1030.532600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1094.851300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1048.700400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1088.713000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>997.152700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1065.942400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1094.087700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1088.829700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1095.968000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1073.472800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1078.892500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>998.573000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1063.733100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1027.824900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1079.609400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1040.529400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1048.996500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1020.191200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1080.953400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1063.312100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1021.056100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1005.803000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1108.903800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1110.724000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1019.923300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1070.553500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1081.057800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1005.371800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>995.533400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1027.754600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>974.619700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1017.963700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2278.628900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1144.216400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1103.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1052.447100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1015.152400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>984.246400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1055.685500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1074.428300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1033.252100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1081.136500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1000.500500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2301.517600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1160.448400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1115.129400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1057.689800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1058.807700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1015.838200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1006.851800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1023.458200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1105.488100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1055.515200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1014.809800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1068.813100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1047.312300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1017.358900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1021.555900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1078.953900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1083.173800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1101.048300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1040.178500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1002.802700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1076.600300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2247.578900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1170.044400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1056.201900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1073.385900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1052.497800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1057.321600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1042.739100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1032.578600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1010.634200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1063.981400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1192.613300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1049.962100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1021.432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1082.332000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1102.342600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1059.428600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1138.264800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1070.504700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1053.658500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1010.614300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1066.968800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1039.895700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1131.672700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1094.663900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1018.469400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1043.918700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1017.910100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1078.537700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1047.039700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1144.052100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>969.242300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1129.874000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1062.382600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1105.980100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1069.568700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1061.852000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1026.501400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1013.414600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2229.390600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1091.852100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1141.314400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1044.908300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1009.023800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1116.280200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>952.585000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>955.172300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1124.577500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>985.364900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1073.697900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1037.363300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1050.694900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>991.412300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1044.417500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1106.676200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1032.990200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1013.239800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>976.719500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1041.323600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=1.0000, CER=0.9949, SER=1.0000\n",
      "Round 1, =0.0720, =22096.5290, WER=1.000, Loss=1109.1305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2114.304700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1887.158200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1778.319300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1835.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1816.153300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1838.012100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1861.301800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1956.018200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1902.017000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1845.943700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1715.774800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1868.176600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1804.789600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1801.899800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1862.932400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1709.925200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1741.322500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1695.842000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1752.627000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1631.908800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1801.752500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1646.984400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1752.293900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1664.827700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1762.832000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1708.802100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1659.755900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1793.959000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1779.614100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1819.565000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1654.266800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1814.353100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1738.618000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1620.669300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1576.702900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1612.930900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1551.633300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1449.965600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2148.853100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1907.756100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1904.567800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1833.442800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1845.954700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1786.298400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1876.103500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1895.891400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1873.472300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1876.967200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1764.314100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2097.763500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1952.892000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1884.965400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1836.769300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1950.971900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1762.993600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1848.144300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1886.787900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1923.296900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1855.464500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1797.010500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1855.353500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1773.793400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1793.086700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1746.068700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1824.765200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1778.910700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1752.739100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1725.857000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1645.507400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1802.480900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2201.618200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2029.473000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1853.097700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1981.121300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1870.289300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1798.093400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1865.628500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1871.776800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1800.549400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1866.796500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2053.127000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1799.712300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1787.807400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1903.679900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1883.497300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1836.102300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2012.166400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1849.469900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1854.408000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1741.326400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1900.735200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1799.568400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1977.813900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1964.298000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1785.368600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1815.352500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1762.822500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1803.248400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1731.066000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1863.668900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1667.788100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1785.444500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1717.771900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1775.125400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1761.604700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1825.210500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1706.419500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1682.019900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2169.307400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1818.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1972.101600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1875.373600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1795.548000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1976.468600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1709.580700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1715.824400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1956.462100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1798.518600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1870.503500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1784.568000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1837.807200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1784.264500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1763.660500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1888.803100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1739.471300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1749.204700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1642.993000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1723.681400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=1.0000, CER=0.9950, SER=1.0000\n",
      "Round 2, =0.0720, =44081.2798, WER=1.000, Loss=1824.6331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2128.736900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1956.538300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1849.410700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1886.525800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1868.020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1893.847300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1910.826600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2009.214600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1972.572100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1923.388500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1801.889800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1973.235000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1923.360200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1921.583400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1983.649000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1864.868400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1881.651000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1804.283800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1912.406200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1780.894300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1926.211300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1808.072100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1861.446300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1811.277300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1934.581200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1887.932200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1799.386500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1910.059600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1946.826800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1600.177200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1377.481600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1424.206400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1451.561800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1353.238300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1336.552800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1364.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1315.565000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1364.207400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2083.301200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1478.971500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1435.527200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1376.306900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1337.660400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1283.386000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1376.726200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1401.684400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1349.849800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1409.639600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1315.668800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2130.997700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1488.791300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1450.846200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1388.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1395.614600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1326.555700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1318.741800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1340.478000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1446.390500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1379.552700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1321.293800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1400.397400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1358.413500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1329.982800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1295.353200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1260.506300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1269.077600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1251.364500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1174.571700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1122.182300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1191.303100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2287.652900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1551.362100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1096.182200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1078.557800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1057.124000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1062.945200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1053.963100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1037.312900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1021.954600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1066.295000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1198.408100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1054.900900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1030.399500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1086.114600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1107.917100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1063.752100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1145.455500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1075.695100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1059.355300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1015.231300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1073.093700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1048.682200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1138.781600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1099.904600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1024.817600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1050.507200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1023.584700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1084.801200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1053.217300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1152.220900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>978.461100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1138.460100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1074.486200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1119.556700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1086.385500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1078.661300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1043.457800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1031.122000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2178.729300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1948.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2045.660500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1949.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1854.127700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2022.153100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1754.720700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1756.979300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1612.342200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1052.799400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1087.826000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1042.973000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1054.243000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>995.897700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1048.943200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1113.186100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1038.184700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1017.129200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>981.712200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1046.606400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=1.0352, CER=0.9763, SER=1.0000\n",
      "Round 3, =0.0720, =66066.0305, WER=1.035, Loss=1421.4903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1427.132000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1158.315700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1102.385200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1037.644500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1086.332400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1039.545500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1063.483300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1127.194700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1077.512900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1120.862200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1024.583700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1096.586900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1111.657200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1112.443200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1122.100700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1093.960700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1101.011500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1024.029100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1085.858400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1050.866700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1099.309300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1059.985600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1068.561700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1037.110100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1099.959500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1083.855500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1041.693800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1025.442400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1131.933600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1135.701900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1042.260400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1094.058400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1108.426700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1034.868300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1026.350500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1059.942500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1007.192300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1052.017400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1421.745500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1161.520800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1145.142300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1088.446100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1054.332800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1013.353700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1091.935500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1108.650400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1062.252900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1109.640600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1027.230800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1391.127300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1160.991000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1154.658600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1101.128900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1107.213300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1052.751800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1045.075600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1056.180500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1138.210600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1088.497900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1040.046700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1098.710900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1069.363600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1047.964800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1049.181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1100.328000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1107.029500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1126.597500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1065.836600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1027.919800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1099.976300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1449.594800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1174.554400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1093.519100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1111.220600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1085.302000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1090.197500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1077.464100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1066.270600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1040.475200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1089.830600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1221.093900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1073.608800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1043.393400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1105.410900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1124.592600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1080.877400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1160.576900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1089.939300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1073.120600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1028.011300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1084.983400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1057.817100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1154.686800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1115.300500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1037.398600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1062.048400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1036.649500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1098.657800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1067.824600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1166.609800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>989.316100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1152.529300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1088.462300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1132.444400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1099.365700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1090.396300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1055.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1042.539500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1411.977500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1111.267800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1204.519100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1096.673300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1040.389600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1155.851900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>977.821500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>984.028600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1154.078900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1010.043500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1104.785100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1060.280800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1072.607500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1013.252500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1071.242500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1132.424200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1056.383300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1032.225400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>999.772300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1062.761600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=1.0000, CER=1.0000, SER=1.0000\n",
      "Round 4, =0.0720, =88050.7813, WER=1.000, Loss=1096.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1351.683100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1216.438100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1171.895100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1089.108400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1142.341900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1087.351300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1112.170900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1171.268000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1122.096300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1166.179500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1059.679300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1140.139100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1152.044700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1149.716700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1155.456100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1125.743100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1134.816400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1052.712300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1114.773200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1077.488100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1130.645800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1093.733400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1098.240600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1064.948600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1130.074500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1111.304700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1066.367100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1050.696200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1159.327200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1162.871700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1066.612100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1117.919500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1134.260700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1058.558600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1048.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1086.123800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1028.102400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1076.903600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1388.160800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1216.047600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1202.678400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1156.957900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1114.420500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1069.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1141.912200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1159.348400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1110.665200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1166.378200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1076.316600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1377.977000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1237.480100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1245.978300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1164.863200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1153.040900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1103.203800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1092.839500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1104.330500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1185.659700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1134.642400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1083.650200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1142.467600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1109.373700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1083.499000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1086.319000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1143.082400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1148.613100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1165.661000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1098.307300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1065.005800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1137.697500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1375.660500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1237.991200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1150.205500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1178.413500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1149.124200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1148.475700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1120.717300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1105.198300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1088.363200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1134.308100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1264.565400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1115.126600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1083.860600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1143.154000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1160.877300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1113.018100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1197.585200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1125.398600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1105.313300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1055.534800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1119.969800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1084.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1187.443700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1140.963100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1061.294800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1087.952500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1065.310700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1124.560500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1091.253200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1191.665200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1011.006300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1181.754100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1115.271500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1162.354200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1128.112200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1114.822900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1077.760400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1065.403900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1382.699300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1170.424800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1265.323600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1147.908600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1097.501700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1210.663300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1032.302600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1033.479500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1206.193500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1054.115300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1142.202700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1105.200600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1116.736700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1057.271300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1114.294900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1174.042000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1096.530300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1073.196800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1037.813500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1103.219100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=1.0000, CER=1.0000, SER=1.0000\n",
      "Round 5, =0.0720, =110035.5321, WER=1.000, Loss=1135.8854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1367.574300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1289.916900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1226.156600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1154.525400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1212.707900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1156.482300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1178.466400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1243.283600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1188.535500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1227.637000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1114.653100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1197.749900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1214.683300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1202.112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1213.460800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1181.602400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1192.606300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1099.592300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1168.392700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1126.939800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1178.472900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1140.146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1142.157700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1113.047100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1174.392100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1153.965800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1112.114500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1090.181200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1207.586700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1206.170800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1107.937800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1163.204000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1177.839300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1099.468200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1084.907900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1123.800400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1065.008300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1115.720700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1434.689600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1284.748500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1273.143800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1213.892400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1163.800100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1130.560300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1205.890800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1230.671700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1177.152500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1232.546700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1142.299000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1396.099500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1292.376400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1278.610800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1213.239200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1213.994800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1170.407200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1144.870900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1158.530700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1243.833600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1193.246000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1135.661600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1194.446700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1167.430400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1129.952700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1140.833900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1195.919500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1197.045900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1219.326700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1152.783300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1113.217700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1185.988600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1406.555500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1304.306000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1214.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1234.082300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1210.552000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1213.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1185.941700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1165.740200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1139.794500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1187.882200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1331.481100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1171.509200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1135.023300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1200.863900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1215.509900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1167.382600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1257.685400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1171.203500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1149.740300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1100.645100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1169.261600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1131.737300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1234.351600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1184.549200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1101.852900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1129.710900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1105.558900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1166.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1131.028000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1241.237700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1048.618000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1225.834000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1155.840100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1201.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1165.621300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1155.523400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1117.767800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1104.579800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1387.571500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1221.545300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1313.288800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1207.549300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1157.410200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1277.360400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1084.132000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1088.241500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1271.836900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1108.948600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1204.596400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1167.219700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1177.360800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1107.955500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1163.635600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1235.796300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1148.529500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1125.461200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1083.753500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1160.701600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=1.0000, CER=1.0000, SER=1.0000\n",
      "Round 6, =0.0720, =132020.2828, WER=1.000, Loss=1189.2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1443.555400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1362.081300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1313.070700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1238.653600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1294.949000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1245.529600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1256.934600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1318.735700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1263.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1306.563500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1195.219900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1271.044500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1284.164300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1279.308400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1284.008900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1254.236200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1259.903800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1161.812200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1232.806300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1185.094300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1252.166500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1201.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1209.373500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1169.695500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1244.714900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1218.451500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1170.425300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1142.618000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1270.907300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1270.840400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1168.929100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1222.897800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1239.793700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1158.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1142.650200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1181.704100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1116.651000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1171.571400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1489.293000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1372.384000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1356.009100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1292.020300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1259.500500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1202.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1293.678700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1311.288100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1256.152400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1319.956100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1215.514400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1470.090500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1382.772600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1365.555000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1300.247300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1295.554100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1242.217300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1225.698800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1240.973400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1335.129800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1281.971700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1209.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1278.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1252.703100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1207.123000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1214.220300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1273.728200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1281.734600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1303.890600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1229.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1184.489300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1261.771300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1494.041500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1394.652900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1305.184800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1323.711100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1292.235500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1294.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1265.475200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1237.608200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1214.287000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1269.827700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1424.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1253.339300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1205.751500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1272.587100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1296.736100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1237.377400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1320.891500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1251.850600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1219.833000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1169.313900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1238.363500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1203.339800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1308.956400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1255.138200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1162.246200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1189.475700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1165.709600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1228.720700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1198.891200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1308.218400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1107.056300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1299.409000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1217.343700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1267.372200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1223.405200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1211.847500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1175.525000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1160.462900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1463.773700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1305.065300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1407.478900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1287.310900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1234.407600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1369.052200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1155.289000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1164.753100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1345.773700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1181.178800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1281.151800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1240.217900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1249.680300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1176.161300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1241.224400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1311.630900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1221.872800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1193.288800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1151.990400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1227.610400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=1.0000, CER=1.0000, SER=1.0000\n",
      "Round 7, =0.0720, =154005.0336, WER=1.000, Loss=1264.3562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1529.041900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1476.150300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1422.896100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1337.212100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1401.093400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1344.228800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1353.176800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1420.707700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1359.331900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1401.693900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1274.130800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1370.385600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1377.248500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1375.188300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1377.676600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1348.051200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1355.317300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1249.532100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1320.760400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1278.332200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1334.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1292.028400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1298.382300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1252.809700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1333.129800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1306.568600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1255.431000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1226.347100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1357.649900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1358.598700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1246.025600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1307.627000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1325.699000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1230.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1213.332200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1261.348800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1192.186300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1251.414700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1568.448000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1464.816900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1468.708900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1410.368100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1367.115900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1306.077700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1393.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1420.042600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1364.016800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1427.648000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1315.815600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1583.200400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1483.579500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1480.538000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1402.157600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1402.488100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1348.278900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1329.841500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1335.377600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1442.633400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1367.585200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1310.834400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1382.011100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1347.993000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1305.745600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1307.147300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1374.496900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1379.314300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1399.306300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1323.199200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1273.139800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1362.935400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1594.310400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1492.367800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1401.827100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1417.498200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1395.122900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1408.854900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1362.614800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1337.076200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1303.247200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1365.763300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1528.246800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1339.152300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1295.866200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1371.634100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1381.165400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1328.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1415.927400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1334.586500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1308.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1245.469600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1311.812000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1282.471100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1398.679900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1337.772500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1238.459600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1271.905300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1242.023400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1312.820900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1270.776700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1390.372000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1175.313100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1375.910700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1296.613900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1344.756600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1299.224300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1282.340800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1250.634600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1233.764200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1562.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1413.911600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1530.934400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1395.084000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1331.426700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1486.804800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1255.021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1259.839400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1452.792900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1277.497500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1385.673600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1334.865000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1342.334200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1270.775500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1342.905100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1415.566600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1315.721400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1292.878500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1242.802100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1331.750800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=1.0000, CER=1.0000, SER=1.0000\n",
      "Round 8, =0.0720, =175989.7844, WER=1.000, Loss=1360.3759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1662.369700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1613.123900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1553.945700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1454.373400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1531.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1467.533000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1491.049500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1562.497500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1491.201200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1541.705200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1406.376800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1497.191400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1515.535500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1502.665800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1513.539600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1487.577400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1488.076600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1365.552900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1449.086100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1395.029700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1463.931100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1412.448300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1417.311300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1364.947000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1453.057200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1423.911000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1365.093800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1336.835700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1475.057500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1482.268900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1364.112700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1427.899000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1446.807400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1339.771800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1328.389300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1381.883900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1299.960800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1358.784100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1709.789500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1620.971500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1619.091400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1538.639700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1483.827100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1431.107500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1530.503100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1557.871700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1482.404500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1567.093700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1443.019800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1725.124000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1623.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1616.017700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1521.493700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1529.121300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1479.424300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1451.111100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1466.136900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1583.736800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1499.135200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1429.700400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1500.602100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1468.548700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1426.831600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1435.733200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1501.478500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1509.336700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1532.343000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1446.923700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1396.173900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1479.706900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1737.432800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1641.393400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1537.117800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1564.853000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1525.919700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1535.092900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1495.531200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1462.320800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1433.029400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1490.802300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1667.493900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1474.551000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1429.065600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1498.902000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1519.950100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1456.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1555.202300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1457.615800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1430.661700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1364.098700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1430.458800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1401.711200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1522.874800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1466.459600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1352.931800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1384.974800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1355.114800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1421.102500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1385.490600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1516.584900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1277.683500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1501.821700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1415.684500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1471.116500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1427.151600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1401.836200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1362.342600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1350.767100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1684.477900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1538.451300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1673.252000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1516.232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1464.754800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1623.985800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1362.185000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1372.194500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1596.281900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1387.617400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1505.318500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1457.897700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1473.996200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1395.032500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1464.308100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1539.849000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1433.338400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1411.010700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1357.348600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1450.871700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=1.0000, CER=1.0000, SER=1.0000\n",
      "Round 9, =0.0720, =197974.5351, WER=1.000, Loss=1487.1128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1838.171700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1771.707200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1711.867400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1614.679500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1692.041400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1624.204000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1655.041000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1729.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1642.012900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1699.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1541.285400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1651.110900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1672.009200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1663.727500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1677.182400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1643.516600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1640.275800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1506.105900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1599.897700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1540.731700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1623.529500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1560.665800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1560.247600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1505.161800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1607.795600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1583.834000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1518.810300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1474.464200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1632.597700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1635.709900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1504.769700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1573.770200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1598.169800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1477.872900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1466.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1520.614500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1446.542800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1508.813500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1882.977000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1783.972700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1785.353900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1693.666800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1638.914500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1574.232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1686.670100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1719.496300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1650.908800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1718.655900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1594.032800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1893.663500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1800.729300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1813.130500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1693.072700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1683.536700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1618.590200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1597.080300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1622.682900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1740.154700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1656.135400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1601.850900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1666.064500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1623.213600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1580.172500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1585.518000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1655.494500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1661.499600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1697.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1603.534400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1546.880900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1639.880700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1919.984800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1797.846900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1703.823400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1730.658000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1683.862500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1690.965600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1649.632800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1628.565400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1604.317100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1654.072900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1837.197500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1634.118600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1571.114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1663.322700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1676.391400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1615.646100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1720.794500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1602.138200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1578.746800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1510.278600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1595.805200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1560.738100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1694.044500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1616.759600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1501.244900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1540.704500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1502.677000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1578.943600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1527.469000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1677.842800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1419.262900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1655.598200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1573.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1630.521500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1571.911200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1550.532800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1507.296200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1490.078800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1858.418900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1699.090600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1828.798400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1668.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1615.039900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1797.416200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1509.621800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1516.411000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1766.564500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1543.366500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1676.242800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1615.425200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1632.899900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1539.370600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1623.189000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1705.760700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1582.739700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1550.400800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1495.911600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1593.497800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=1.0000, CER=1.0000, SER=1.0000\n",
      "Round 10, =0.0720, =219959.2859, WER=1.000, Loss=1643.1935\n",
      "[S_11_z_0.005] Using S=11, z=0.005, sigma=0.0880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2269.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1143.165700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1067.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1000.734100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1053.445600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1006.359600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1030.532400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1094.851400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1048.700300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1088.712300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>997.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1065.918300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1094.126700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1088.873800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1096.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1073.535100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1078.986400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>998.468300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1063.666700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1027.785600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1079.620800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1040.568300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1049.030500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1020.235400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1081.007400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1063.388000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1021.100600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1005.886900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1109.032200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1110.871700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1020.096500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1070.786900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1081.370400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1005.709000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>995.888500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1028.120700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>974.979500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1018.383100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2278.629100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1144.216500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1103.274900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1052.447100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1015.152500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>984.246500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1055.685700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1074.428500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1033.251900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1081.136600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1000.500500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2301.517600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1160.448500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1115.129500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1057.689800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1058.807700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1015.838200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1006.851700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1023.458400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1105.487900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1055.515800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1014.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1068.813800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1047.312100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1017.358200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1021.555100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1078.953800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1083.174700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1101.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1040.178400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1002.802300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1076.599900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2247.580900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1170.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1056.201700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1073.385700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1052.497900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1057.321400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1042.739100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1032.578500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1010.634300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1063.982100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1192.612400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1049.962400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1021.431500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1082.331800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1102.342700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1059.428300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1138.268100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1070.505900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1053.662400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1010.615100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1066.969800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1039.889600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1131.670400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1094.666000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1018.469000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1043.918300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1017.910900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1078.537200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1047.040900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1144.051600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>969.241900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1129.865800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1062.375600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1105.964800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1069.555000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1061.838100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1026.487100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1013.402900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2229.391000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1091.852000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1141.314200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1044.908400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1009.023600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1116.280100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>952.585400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>955.172400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1124.577500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>985.365000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1073.697900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1037.363400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1050.695000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>991.412300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1044.417100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1106.676300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1032.990200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1013.240300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>976.719800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1041.323800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=1.0000, CER=0.9950, SER=1.0000\n",
      "Round 1, =0.0880, =22096.5290, WER=1.000, Loss=1109.1482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2141.766800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1892.187900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1783.608400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1879.793600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1845.789500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1848.533600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1871.764600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1969.516200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1925.091400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1891.118400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1769.741800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1940.192800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1887.974400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1890.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1946.699000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1836.870700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1853.695300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1784.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1885.591200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1759.495100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1909.588100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1784.540400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1839.513700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1792.767400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1918.159800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1864.525800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1780.858600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1928.815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1967.966600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1989.918000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1843.227100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1979.476200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1889.832000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1792.009800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1737.537100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1784.519700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1817.775600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1817.356400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2199.444700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1928.768900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1936.697100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1840.668900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1876.321700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1794.396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1891.732200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1909.799000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1888.151800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1893.051200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1775.428500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2140.664500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1958.835200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1898.900200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1850.453700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1967.659000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1778.125800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1853.204300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1882.569700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1935.869700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1887.432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1848.066800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1906.705100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1861.919900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1873.784000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1821.953100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1919.607000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1891.173000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1876.657000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1826.184600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1752.293400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1915.161300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2263.346300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1676.617600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1094.094000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1083.473500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1059.695400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1057.005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1044.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1033.653500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1014.433000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1063.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1194.199700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1057.165600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1024.240200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1087.069500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1103.929100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1062.402100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1139.729800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1073.973100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1056.969900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1012.689600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1068.469300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1044.431200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1136.017900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1096.992100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1020.299500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1046.760300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1022.258600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1082.058400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1050.867900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1150.348600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>975.192700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1135.756000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1070.700600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1116.807500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1083.349800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1075.281200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1041.184900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1027.468500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2263.763100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1845.531100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1986.761900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1886.841600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1802.494100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1982.178900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1724.238500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1726.578700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1984.860200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1833.837100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1927.068900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1846.987700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1908.180300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1844.069700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1843.299400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1973.797700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1830.081100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1828.792400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1719.397500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1818.500400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=1.0000, CER=0.9950, SER=1.0000\n",
      "Round 2, =0.0880, =44081.2798, WER=1.000, Loss=1727.5713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2174.157200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1492.646900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1421.538400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1337.549500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1399.877700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1338.252200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1375.446500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1448.591300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1378.617500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1431.888700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1317.654300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1410.954900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1430.923800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1433.791200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1444.860200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1415.321200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1415.952600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1315.465000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1403.752400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1351.803700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1421.376800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1367.820400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1382.172900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1339.524900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1421.451600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1399.470400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1347.521800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1332.226500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1474.011100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1467.199300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1356.324400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1414.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1433.849900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1339.853100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1325.326900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1370.537100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1315.086600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1366.872800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2172.419900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1523.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1471.938400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1406.196500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1362.153700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1303.910800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1393.651100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1420.643100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1369.420300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1427.903200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1334.439000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2333.136900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1611.585400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1190.334400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1077.606800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1079.431000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1033.505900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1021.908100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1039.518300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1120.729700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1069.056300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1031.632400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1082.906600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1056.158700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1027.551900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1034.386200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1089.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1092.623500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1111.860900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1051.986900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1016.961300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1088.477300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2238.346100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1573.398200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1413.349800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1445.622900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1411.566100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1395.620800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1382.308400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1367.388900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1338.608600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1400.788900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1574.691400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1386.695200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1353.193400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1425.901500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1441.397600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1395.049800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1493.461900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1408.971000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1393.645100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1336.400600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1407.809600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1377.704900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1488.527900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1434.806900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1350.991300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1377.303100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1341.660500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1420.963600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1381.588500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1499.236900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1289.106300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1484.659600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1402.702100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1461.626500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1420.590500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1410.775900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1368.305300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1344.137900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2013.554700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1442.143800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1529.231300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1396.292900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1347.511100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1478.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1263.488300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1271.563800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1491.467900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1305.728600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1423.983400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1367.730300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1395.660300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1305.845200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1372.160400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1467.401500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1370.271600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1334.073200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1288.537100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1374.738300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=1.6021, CER=0.9825, SER=1.0000\n",
      "Round 3, =0.0880, =66066.0305, WER=1.602, Loss=1372.7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2132.255500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1649.748200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1553.255300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1449.506100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1504.375200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1436.644400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1461.710900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1533.219300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1450.261700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1505.342700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1378.833200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1471.918900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1489.182200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1485.997200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1501.197300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1465.354200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1463.408700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1364.762700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1451.230300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1390.335400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1462.142100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1407.762400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1421.604200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1373.437100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1459.957400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1434.326400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1382.079700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1366.104500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1509.919500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1501.454000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1388.392800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1448.756900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1467.843700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1369.341500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1355.500800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1401.332700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1343.393200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1398.173200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2335.142800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2001.467800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1947.748400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1854.857200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1781.682000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1701.592000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1811.472500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1828.891000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1784.747100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1827.115400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1717.160900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2267.708800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1996.761100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1964.530700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1844.229300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1869.899400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1744.298000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1727.438900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1763.928700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1857.235500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1775.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1692.681600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1796.645700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1737.593200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1703.168200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1683.394500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1795.835500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1757.471100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1800.774000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1700.536100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1638.009900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1780.212500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2332.719900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2062.962700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1866.312900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1901.046300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1843.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1812.687100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1777.657000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1752.336500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1708.971300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1776.424200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1995.578500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1736.609800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1696.536700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1773.836500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1788.923200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1725.414500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1846.503100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1737.465200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1707.100200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1646.954500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1744.881400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1671.959800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1807.882200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1760.726400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1642.438500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1675.780900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1637.390300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1729.498200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1666.288700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1819.041600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1568.914000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1802.149600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1690.986300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1768.150800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1716.095300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1713.977900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1652.586500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1633.185700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2281.565400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1913.929100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2019.833600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1835.726000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1753.140400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1886.835700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1626.730700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1654.507400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1914.531600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1649.652700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1815.052300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1721.951200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1750.171100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1652.409400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1711.696500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1840.047100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1705.590400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1678.059000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1614.768200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1704.047300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=0.9999, CER=0.9946, SER=1.0000\n",
      "Round 4, =0.0880, =88050.7813, WER=1.000, Loss=1734.6974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2305.527300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2086.775200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1994.062100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1917.045300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1954.854500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1862.251000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1875.801200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1969.612100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1881.515000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1947.052000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1784.297100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1886.110900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1914.655100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1928.251600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1904.246700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1862.883600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1846.645100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1727.391800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1837.158000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1772.930100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1854.343600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1787.987900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1778.075800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1715.389800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1827.653700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1818.736100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1718.238700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1717.226800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1878.439300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1855.136300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1731.120900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1780.860400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1828.467600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1705.042400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1699.274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1744.465000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1660.794900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1750.366400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2292.547500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2120.465600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2078.293700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1991.760900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1922.823600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1833.814300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1948.528900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1970.942400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1925.466000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1966.324400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1848.814300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2355.785500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2121.564600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2092.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1973.742000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2009.842200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1866.233400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1850.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1895.119300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1989.549400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1902.309400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1814.485500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1923.048200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1858.435500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1822.653900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1791.242600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1914.582000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1875.668600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1920.057800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1813.234000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1747.983600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1894.449400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2374.120500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2158.958800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1983.325600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2020.480100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1969.852100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1935.341400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1884.987900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1871.855100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1828.843400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1894.785500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2121.158000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1855.519500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1809.479900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1886.318700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1894.766400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1827.420100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1955.156800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1838.585500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1802.316800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1734.507000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1839.060400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1759.050800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1905.746900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1853.096500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1725.129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1756.664600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1719.043200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1816.582600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1747.995900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1905.767400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1645.735400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1893.794900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1766.236100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1852.557600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1797.793200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1798.258800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1731.960500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1711.673000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2353.489600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2036.171500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2159.641400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1959.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1881.918900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2033.435500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1748.661700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1779.320100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2056.781200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1773.780300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1949.422300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1846.375600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1877.858800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1769.945900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1833.475800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1970.708400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1826.544500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1794.972100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1733.127100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1818.615600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=0.9999, CER=0.9946, SER=1.0000\n",
      "Round 5, =0.0880, =110035.5321, WER=1.000, Loss=1902.8591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2500.707800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2264.380700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2167.844900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2081.778300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2132.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2038.902900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2050.902300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2156.626800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2048.979900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2127.892600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1939.893700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2051.588300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2079.128900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2098.759200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2066.838900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2023.002900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1998.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1871.244500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1993.992400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1912.883400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2000.855100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1932.243000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1913.210400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1842.712100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1965.048600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1963.281800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1849.698000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1848.116600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2015.249600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1989.611900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1859.380500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1911.899400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1962.803500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1825.210200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1819.462900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1872.420300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1779.889500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1881.017600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2482.959400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2312.358600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2256.723200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2167.496700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2083.173800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1991.667400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2119.204100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2150.735500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2089.901000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2148.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2017.362100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2562.451200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2304.718000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2271.296700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2149.332200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2191.451800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2038.121500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2030.276600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2068.063700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2171.161100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2078.682800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1978.660200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2100.854700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2031.831200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1989.570300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1953.511500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2089.416400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2037.347100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2090.894900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1973.058200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1903.485200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2065.564800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2589.661100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2373.991800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2170.587500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2199.871300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2148.420700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2109.571100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2059.368900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2049.842000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2002.587100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2073.687300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2318.070900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2030.415400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1977.486100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2057.730900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2062.172100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1992.829500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2122.689300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1998.836500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1956.591000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1880.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1991.772700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1903.611500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2057.484400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1999.941800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1862.110900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1903.654300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1861.663300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1960.351800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1883.850800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2055.550800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1773.084600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2042.999200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1901.431600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1998.680900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1937.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1937.043400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1860.792200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1843.211900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2534.342200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2211.597900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2339.808600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2134.016400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2050.848600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2214.252100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1905.681600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1939.117200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2246.690200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1937.070900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2124.781600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2018.681800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2042.522500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1931.977100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1994.562300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2146.968900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1983.402000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1952.170900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1883.995500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1975.892400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=0.9999, CER=0.9946, SER=1.0000\n",
      "Round 6, =0.0880, =132020.2828, WER=1.000, Loss=2067.9257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2712.365600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2517.506400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2418.343000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2325.529300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2377.076600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2272.535900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2278.295700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2406.520700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2284.967800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2356.015800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2164.482600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2285.555300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2312.191000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2335.949400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2295.926600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2245.648800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2220.891400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2075.053700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2207.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2119.852300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2224.056800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2137.004100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2125.510200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2042.773600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2175.542800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2177.028500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2046.741600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2040.772900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2225.731100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2196.458600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2055.664100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2107.465200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2160.501000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>2010.634000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2006.176400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2067.715600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1965.809800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2077.646900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2664.388900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2540.147300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2510.483800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2416.907600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2330.787700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2222.344100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2362.174200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2395.919100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2332.016200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2394.157600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2246.912300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2762.177700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2543.279700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2520.705100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2396.043400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2439.528900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2260.786300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2260.111900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2306.582600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2418.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2309.242400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2202.494500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2350.673800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2259.599200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2205.914600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2175.170900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2327.810900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2270.285700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2328.714300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2193.284400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2114.142800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2296.274000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2789.757000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2613.510900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2410.090600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2448.534000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2390.882600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2344.620900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2286.691800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2270.275600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2229.659600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2307.821700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2574.860200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2254.185700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2190.683600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2281.801800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2286.791200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2223.464100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2357.477000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2214.851400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2168.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2081.986900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2202.051600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2103.598400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2274.887700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2217.475200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2052.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2105.479100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2059.061100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2163.447700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2077.295500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2272.252300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1959.851400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2255.943900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2093.245700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>2202.670700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2135.373800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2139.826400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2050.869100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2031.118200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2738.880700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2444.562300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2609.212900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2369.987100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2283.592200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2472.164600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2134.806400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2160.860500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2500.018600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2166.488300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2371.154900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2249.478900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2280.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2152.999600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2230.072900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2407.634000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2214.150800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2171.176600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2100.134800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2204.090600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=0.9999, CER=0.9946, SER=1.0000\n",
      "Round 7, =0.0880, =154005.0336, WER=1.000, Loss=2294.3021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3005.885500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2826.909600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2720.996700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2627.854100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2681.583800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2563.473000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2581.916400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2728.108600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2581.303300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2673.368000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2448.268900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2583.295700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2619.628900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2649.016400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2596.617200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2550.620700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2513.724800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2353.063100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2500.026200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2399.120700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2521.685700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2425.641200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2406.581100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2319.349200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2468.143400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2463.286300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2320.864300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2312.352700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2523.658800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2487.760500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2328.707200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2386.908800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2447.990200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>2270.197500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2270.669500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2342.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2225.150600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2347.732200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2982.567200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2871.178100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2839.434400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2730.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2642.934000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2530.822700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2676.546700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2716.582200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2649.642800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2711.830700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2543.178500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3078.043700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2869.503700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2859.868900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2726.861100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2765.936700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2566.497100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2563.932400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2617.103300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2748.347700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2615.059000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2504.204900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2666.655500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2571.784800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2505.229900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2472.747700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2645.210400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2582.504300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2648.098400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2494.060700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2404.385400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2607.954500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3106.553900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2942.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2719.278700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2764.023200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2700.282000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2648.248600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2591.060200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2574.641800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2525.428900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2625.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2917.103300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2563.551200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2476.723400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2589.454500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2589.501600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2518.812100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2674.773400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2505.160500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2451.433000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2353.048400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2497.452900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2386.353900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2575.414500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2505.601600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2322.624200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2386.636700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2327.083200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2455.549800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2352.543700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2582.424000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2223.615200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2558.036900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2370.339100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>2492.080700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2418.995300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2419.006600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2320.754700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2288.524800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3040.520700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2738.335500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2931.351200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2671.909400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2572.698200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2785.598400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2404.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2436.205500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2821.457400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2442.480500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2666.738300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2521.760500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2566.645300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2420.878700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2509.198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2708.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2494.834400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2451.559400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2375.644900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2484.962500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=0.9999, CER=0.9946, SER=1.0000\n",
      "Round 8, =0.0880, =175989.7844, WER=1.000, Loss=2594.4188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3411.664500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3224.484600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3098.898800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2996.617800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3067.266800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2939.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2963.139800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3126.095500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2947.842200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3081.660200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2816.435700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2964.247100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3014.945100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3052.466800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2986.539100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2932.970900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2902.728500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2709.098200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2872.483800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2761.742800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2898.955500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2792.848600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2772.065800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2670.197900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2840.298800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2830.278100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2666.898600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2665.078100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2924.413300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2866.792200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2684.447100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2742.411300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2825.025400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>2616.776000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2607.021700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2699.471700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2566.132200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2702.541000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3421.527300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3264.558400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3235.705900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3119.102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3022.975400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2902.351200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3075.083600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3118.106400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3042.887300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3124.021100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2929.751400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3465.265600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3248.802300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3263.267000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3104.616000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3164.981200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2923.209800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2919.524800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2999.288300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3141.537100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2994.173600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2859.768800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3039.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2939.939300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2881.618000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2827.304900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3023.030900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2955.153100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3030.244100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2863.322700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2748.935200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2984.200800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3490.412100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3361.963300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3097.979500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3155.297900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3085.557200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3038.872900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2963.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2946.709000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2906.005100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2997.509600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3352.905100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2938.666400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2857.114100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2981.861500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2980.634400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2908.711500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3077.621100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2892.072700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2831.706300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2722.429500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2872.742600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2751.422300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2970.536900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2882.444900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2685.582000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2751.718800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2681.776600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2824.521700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2715.231600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2980.426600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2577.114300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2951.214100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2737.446100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>2872.523200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2787.006200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2795.815200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2675.764500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2640.465600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3428.660200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3121.187300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3344.711700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3061.077000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2953.132800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3194.165600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2774.349600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2805.525800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3250.003500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2806.984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3073.715200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2910.663700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2945.317600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2788.103500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2895.584400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3138.101600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2869.898200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2828.506600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2734.343600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2864.379500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=0.9999, CER=0.9946, SER=1.0000\n",
      "Round 9, =0.0880, =197974.5351, WER=1.000, Loss=2975.7423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [386/386 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3895.564800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3691.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3553.380500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3449.719100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3525.503900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3378.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3416.299200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3611.108600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3421.840600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3546.707800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3253.459600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3424.241000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3476.923400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3532.554700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3456.620700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3406.186700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3355.743000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3133.341200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3326.311300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3209.834400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3371.037900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3238.951000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>3202.291400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>3089.360500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3295.151600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3298.769100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3090.161500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3088.253100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>3389.109800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3323.593000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>3108.071700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>3184.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>3282.188300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3041.829100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3030.405300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>3126.819900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2978.337100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3136.632600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3875.256600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3749.114100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3706.526600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3591.714100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3474.891000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3332.767600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3526.246500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3584.868000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3505.413700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3594.686700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3384.280500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3969.467200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3742.048400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3746.382000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3578.770300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3641.023800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3379.239100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3381.463300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3461.989500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3634.934800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3450.259000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3298.677700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3516.218000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3395.799600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3321.126600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3280.687900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3497.514800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3414.801600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3505.296900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3299.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3187.573400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3456.514500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3974.444500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3870.274600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3567.476200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3643.187900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3567.618800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3506.268800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3429.818700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3399.714800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3356.794100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3480.437900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3888.988300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3395.448400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3301.039500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3463.916400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3456.013300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3376.105100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3554.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3355.885200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3294.610500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3162.015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3332.713700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3191.238100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>3453.820700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>3350.748400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3119.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3206.259000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3122.734400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3290.421100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>3154.801400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3460.238700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2991.952500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>3436.276200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>3177.664100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3353.741800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3252.396100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>3244.584000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>3117.695900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3068.816600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3909.197700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3570.047700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3846.019100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3509.649600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3395.268000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3679.037100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3198.334200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3233.761300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3745.335500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3245.678900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3545.449200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3362.141000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3401.309800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3224.231200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3347.076200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3606.949600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3312.810900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3265.931800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3163.005700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3311.618800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/mnt/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/utils.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=0.9999, CER=0.9946, SER=1.0000\n",
      "Round 10, =0.0880, =219959.2859, WER=1.000, Loss=3434.0116\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for S in [7, 9, 11]:\n",
    "    label = f\"S_{S}_z_0.005\"\n",
    "    result = train_dp_fedavg(\n",
    "        global_model=base_model,\n",
    "        z=0.005,\n",
    "        S=S,\n",
    "        label=label,\n",
    "        q=0.25,\n",
    "        Wmin=5,\n",
    "        rounds=10,\n",
    "        processor=processor,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        eval_dataset=eval_dataset,\n",
    "        client_datasets=client_datasets,\n",
    "        model_save_path=os.path.join(model_save_path, label),\n",
    "        delta=1e-5\n",
    "    )\n",
    "    results.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32d85bbe-42e0-4d85-b0c0-44dbbe7718bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for res in results:\n",
    "    for i, (wer, eps, loss) in enumerate(zip(res[\"wer_curve\"], res[\"epsilon_curve\"], res[\"train_loss_curve\"])):\n",
    "        rows.append({\n",
    "            \"label\": res[\"label\"],\n",
    "            \"round\": i + 1,\n",
    "            \"S\": res[\"S\"],\n",
    "            \"sigma\": res[\"sigma\"],\n",
    "            \"z\": res[\"z\"],\n",
    "            \"wer\": wer,\n",
    "            \"epsilon\": eps,\n",
    "            \"train_loss\": loss\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(model_save_path + \"/DP_FedAvg_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4af9dd07-b3de-4ada-8d8e-3cb352d1d34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>round</th>\n",
       "      <th>S</th>\n",
       "      <th>sigma</th>\n",
       "      <th>z</th>\n",
       "      <th>wer</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S_7_z_0.005</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22096.529020</td>\n",
       "      <td>1095.467167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S_7_z_0.005</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.063736</td>\n",
       "      <td>44081.279782</td>\n",
       "      <td>1056.971945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S_7_z_0.005</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.000010</td>\n",
       "      <td>66066.030544</td>\n",
       "      <td>1062.009134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S_7_z_0.005</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>88050.781306</td>\n",
       "      <td>1062.952582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S_7_z_0.005</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>110035.532068</td>\n",
       "      <td>1069.588041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S_7_z_0.005</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>132020.282830</td>\n",
       "      <td>1090.006011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S_7_z_0.005</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>154005.033592</td>\n",
       "      <td>1117.405325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S_7_z_0.005</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>175989.784354</td>\n",
       "      <td>1152.027516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S_7_z_0.005</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>197974.535116</td>\n",
       "      <td>1198.210403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S_7_z_0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>219959.285878</td>\n",
       "      <td>1252.830373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S_9_z_0.005</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22096.529020</td>\n",
       "      <td>1109.130503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S_9_z_0.005</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44081.279782</td>\n",
       "      <td>1824.633114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S_9_z_0.005</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.035204</td>\n",
       "      <td>66066.030544</td>\n",
       "      <td>1421.490321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S_9_z_0.005</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>88050.781306</td>\n",
       "      <td>1096.036984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S_9_z_0.005</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>110035.532068</td>\n",
       "      <td>1135.885436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S_9_z_0.005</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>132020.282830</td>\n",
       "      <td>1189.255778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S_9_z_0.005</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>154005.033592</td>\n",
       "      <td>1264.356184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>S_9_z_0.005</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>175989.784354</td>\n",
       "      <td>1360.375902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>S_9_z_0.005</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>197974.535116</td>\n",
       "      <td>1487.112846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S_9_z_0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>219959.285878</td>\n",
       "      <td>1643.193458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>S_11_z_0.005</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22096.529020</td>\n",
       "      <td>1109.148222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S_11_z_0.005</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44081.279782</td>\n",
       "      <td>1727.571303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>S_11_z_0.005</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.602084</td>\n",
       "      <td>66066.030544</td>\n",
       "      <td>1372.752751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>S_11_z_0.005</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>88050.781306</td>\n",
       "      <td>1734.697368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>S_11_z_0.005</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>110035.532068</td>\n",
       "      <td>1902.859145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>S_11_z_0.005</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>132020.282830</td>\n",
       "      <td>2067.925681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>S_11_z_0.005</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>154005.033592</td>\n",
       "      <td>2294.302083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>S_11_z_0.005</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>175989.784354</td>\n",
       "      <td>2594.418784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>S_11_z_0.005</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>197974.535116</td>\n",
       "      <td>2975.742301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>S_11_z_0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>219959.285878</td>\n",
       "      <td>3434.011644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label  round   S  sigma      z       wer        epsilon  \\\n",
       "0    S_7_z_0.005      1   7  0.056  0.005  1.000000   22096.529020   \n",
       "1    S_7_z_0.005      2   7  0.056  0.005  1.063736   44081.279782   \n",
       "2    S_7_z_0.005      3   7  0.056  0.005  1.000010   66066.030544   \n",
       "3    S_7_z_0.005      4   7  0.056  0.005  1.000000   88050.781306   \n",
       "4    S_7_z_0.005      5   7  0.056  0.005  1.000000  110035.532068   \n",
       "5    S_7_z_0.005      6   7  0.056  0.005  1.000000  132020.282830   \n",
       "6    S_7_z_0.005      7   7  0.056  0.005  1.000000  154005.033592   \n",
       "7    S_7_z_0.005      8   7  0.056  0.005  1.000000  175989.784354   \n",
       "8    S_7_z_0.005      9   7  0.056  0.005  1.000000  197974.535116   \n",
       "9    S_7_z_0.005     10   7  0.056  0.005  1.000000  219959.285878   \n",
       "10   S_9_z_0.005      1   9  0.072  0.005  1.000000   22096.529020   \n",
       "11   S_9_z_0.005      2   9  0.072  0.005  1.000000   44081.279782   \n",
       "12   S_9_z_0.005      3   9  0.072  0.005  1.035204   66066.030544   \n",
       "13   S_9_z_0.005      4   9  0.072  0.005  1.000000   88050.781306   \n",
       "14   S_9_z_0.005      5   9  0.072  0.005  1.000000  110035.532068   \n",
       "15   S_9_z_0.005      6   9  0.072  0.005  1.000000  132020.282830   \n",
       "16   S_9_z_0.005      7   9  0.072  0.005  1.000000  154005.033592   \n",
       "17   S_9_z_0.005      8   9  0.072  0.005  1.000000  175989.784354   \n",
       "18   S_9_z_0.005      9   9  0.072  0.005  1.000000  197974.535116   \n",
       "19   S_9_z_0.005     10   9  0.072  0.005  1.000000  219959.285878   \n",
       "20  S_11_z_0.005      1  11  0.088  0.005  1.000000   22096.529020   \n",
       "21  S_11_z_0.005      2  11  0.088  0.005  1.000000   44081.279782   \n",
       "22  S_11_z_0.005      3  11  0.088  0.005  1.602084   66066.030544   \n",
       "23  S_11_z_0.005      4  11  0.088  0.005  0.999950   88050.781306   \n",
       "24  S_11_z_0.005      5  11  0.088  0.005  0.999950  110035.532068   \n",
       "25  S_11_z_0.005      6  11  0.088  0.005  0.999950  132020.282830   \n",
       "26  S_11_z_0.005      7  11  0.088  0.005  0.999950  154005.033592   \n",
       "27  S_11_z_0.005      8  11  0.088  0.005  0.999950  175989.784354   \n",
       "28  S_11_z_0.005      9  11  0.088  0.005  0.999950  197974.535116   \n",
       "29  S_11_z_0.005     10  11  0.088  0.005  0.999950  219959.285878   \n",
       "\n",
       "     train_loss  \n",
       "0   1095.467167  \n",
       "1   1056.971945  \n",
       "2   1062.009134  \n",
       "3   1062.952582  \n",
       "4   1069.588041  \n",
       "5   1090.006011  \n",
       "6   1117.405325  \n",
       "7   1152.027516  \n",
       "8   1198.210403  \n",
       "9   1252.830373  \n",
       "10  1109.130503  \n",
       "11  1824.633114  \n",
       "12  1421.490321  \n",
       "13  1096.036984  \n",
       "14  1135.885436  \n",
       "15  1189.255778  \n",
       "16  1264.356184  \n",
       "17  1360.375902  \n",
       "18  1487.112846  \n",
       "19  1643.193458  \n",
       "20  1109.148222  \n",
       "21  1727.571303  \n",
       "22  1372.752751  \n",
       "23  1734.697368  \n",
       "24  1902.859145  \n",
       "25  2067.925681  \n",
       "26  2294.302083  \n",
       "27  2594.418784  \n",
       "28  2975.742301  \n",
       "29  3434.011644  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(model_save_path + \"/DP_FedAvg_metrics.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffe9bb8f-2a8e-4c5a-ba2b-4090fe96e9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for label in df[\"label\"].unique():\n",
    "    subset = df[df[\"label\"] == label]\n",
    "    plt.plot(subset[\"round\"], subset[\"wer\"], label=label)\n",
    "\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"WER\")\n",
    "plt.title(\"WER by Round for Different Clipping Norms\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1884a5d-d853-43b9-9819-e09fe7d85185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rounds = list(range(1, 11))\n",
    "epsilon_values = [i * 22000 for i in rounds]  # Example growing epsilon values\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Plot the same epsilon curve three times with different colors\n",
    "plt.plot(rounds, epsilon_values, 'o-', label=\"S=7, =0.056\")\n",
    "plt.plot(rounds, epsilon_values, 'o-', label=\"S=9, =0.072\")\n",
    "plt.plot(rounds, epsilon_values, 'o-', label=\"S=11, =0.088\")\n",
    "\n",
    "# Optional: add small text to clarify they're identical\n",
    "plt.text(1.5, epsilon_values[1] + 5000, \"All lines overlap because z=0.005 is fixed\", fontsize=9, color='gray')\n",
    "\n",
    "# Labels and legend\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Epsilon\")\n",
    "plt.title(\"Privacy Loss (Epsilon) Across Rounds\")\n",
    "plt.legend(title=\"Clipping / Noise\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49309db0-5e83-4df6-b8f4-53f8e6ceeaa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot 2: Training Loss across rounds\n",
    "plt.figure(figsize=(8, 5))\n",
    "for config in df[\"config\"].unique():\n",
    "    subset = df[df[\"config\"] == config]\n",
    "    plt.plot(subset[\"round\"], subset[\"train_loss\"], marker='s', label=config)\n",
    "plt.title(\"Training Loss Across Rounds\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.legend(title=\"Clipping / Noise\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
