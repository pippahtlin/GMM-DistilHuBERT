{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e998eaf8-5779-4744-931c-fd950d7b9d31",
   "metadata": {},
   "source": [
    "### Federated Fine-tuning for ASR\n",
    "* Centralized: You fine-tune DistilHuBERT for downstream ASR tasks.\n",
    "* FL: Simulate a federated ASR learning scenario where multiple clients (speakers) fine-tune a shared model on local speech data using FedAvg/FedOpt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19e17708-97c4-46cc-898d-d861af81fc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddaa46a2-3144-4aa0-a272-c6642604ec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "from datasets import load_from_disk\n",
    "from transformers import (\n",
    "    AutoProcessor,\n",
    "    AutoModelForCTC,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from typing import List, Dict\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import random\n",
    "import jiwer\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7964eb38-e7d0-449f-8ffe-461f24b0d74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3dcfed4fb24acd895c3fea7200efd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_from_disk(\"/scratch/pippalin2/jupyter/GMM-DistilHuBERT/processed_dataset\")\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = dataset[\"train\"]\n",
    "eval_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06c2ee39-91c7-4088-9703-b19ab2c6cdeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_values', 'labels'],\n",
       "    num_rows: 25670\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97abe893-61b2-492e-b44c-66f63cff3928",
   "metadata": {},
   "source": [
    "#### Simulating FL setting: clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0cace8a-ae84-416d-b339-d668d90fda47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_clients_nonuniform(dataset, num_clients, min_frac, max_frac):\n",
    "    size = len(dataset)\n",
    "\n",
    "    proportions = np.random.uniform(min_frac, max_frac, size=num_clients)\n",
    "    proportions = proportions / proportions.sum()\n",
    "    sizes = (proportions * size).astype(int)\n",
    "\n",
    "    # Ensure total size matches\n",
    "    diff = size - sizes.sum()\n",
    "    sizes[0] += diff\n",
    "\n",
    "    # Client splits\n",
    "    indices = np.arange(size)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    client_datasets = []\n",
    "    start = 0\n",
    "    for s in sizes:\n",
    "        end = start + s\n",
    "        client_datasets.append(dataset.select(indices[start:end].tolist()))\n",
    "        start = end\n",
    "\n",
    "    return client_datasets\n",
    "client_datasets = split_into_clients_nonuniform(train_dataset, num_clients=20, min_frac=0.01, max_frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "547e725f-9e29-4814-ab4d-efb7705ab427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of HubertForCTC were not initialized from the model checkpoint at ntu-spml/distilhubert and are newly initialized: ['lm_head.bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"/scratch/pippalin2/jupyter/GMM-DistilHuBERT/processor\")\n",
    "base_model = AutoModelForCTC.from_pretrained(\"ntu-spml/distilhubert\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "410b7a2b-edf1-40e8-99dc-7a3bdfbc0894",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCollatorCTCWithPadding:\n",
    "    def __init__(self, processor, padding=True):\n",
    "        self.processor = processor\n",
    "        self.padding = padding\n",
    "\n",
    "    def __call__(self, features: List[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_features = [{\"input_values\": f[\"input_values\"]} for f in features]\n",
    "        label_features = [{\"input_ids\": f[\"labels\"]} for f in features]\n",
    "\n",
    "        batch = self.processor.feature_extractor.pad(input_features, padding=self.padding, return_tensors=\"pt\")\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, padding=self.padding, return_tensors=\"pt\")\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorCTCWithPadding(processor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c0a17c9-e3fb-4893-a8d4-8721ec14098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = \"/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/FedAvg_checkpoints\"\n",
    "os.makedirs(model_save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abe1c812-70dd-4721-9048-c0e93ffd30dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_finetune(model, dataset, processor, collator, compute_metrics, output_dir):\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=model_save_path,\n",
    "        per_device_train_batch_size=2,\n",
    "        eval_strategy=\"no\",\n",
    "        num_train_epochs=2,\n",
    "        eval_steps=400,\n",
    "        logging_steps=10,\n",
    "        save_steps=500,\n",
    "        learning_rate=1e-4,\n",
    "        fp16=True,\n",
    "        resume_from_checkpoint=False,\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset,\n",
    "        tokenizer=processor,\n",
    "        data_collator=collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    train_output = trainer.train()\n",
    "    metrics = {\n",
    "    \"train_loss\": train_output.training_loss,\n",
    "    \"train_steps\": trainer.state.global_step,\n",
    "    }\n",
    "    return model.state_dict(), metrics\n",
    "\n",
    "# uniform weight\n",
    "def fed_avg(state_dicts: List[Dict]):\n",
    "    avg_dict = copy.deepcopy(state_dicts[0])\n",
    "    for key in avg_dict:\n",
    "        for i in range(1, len(state_dicts)):\n",
    "            avg_dict[key] += state_dicts[i][key]\n",
    "        avg_dict[key] = avg_dict[key] / len(state_dicts)\n",
    "    return avg_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee1379e-f71c-4361-a0ca-f80aab192565",
   "metadata": {},
   "source": [
    "Since this simulation involves only 20 clients, using uniform weights helps ensure that each client contributes equally to the global model, avoiding dominance by clients with larger local datasets.\\\n",
    "This choice reduces the risk of model bias toward data-rich clients and promotes fairness â€” especially important in small-scale federated settings where heterogeneity could otherwise overwhelm a few participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec61d43c-3f2e-4b22-85b6-355f52d4ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = jiwer.Compose([\n",
    "    jiwer.ToLowerCase(),\n",
    "    jiwer.RemovePunctuation(),\n",
    "    jiwer.RemoveMultipleSpaces(),\n",
    "    jiwer.Strip(),\n",
    "])\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = torch.argmax(torch.tensor(pred_logits), dim=-1)\n",
    "\n",
    "    # Decode predictions\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "\n",
    "    # Decode references\n",
    "    label_ids = pred.label_ids\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    label_str = processor.batch_decode(label_ids, group_tokens=False)\n",
    "\n",
    "    # Normalize\n",
    "    pred_str = [transform(p) for p in pred_str]\n",
    "    label_str = [transform(l) for l in label_str]\n",
    "\n",
    "    # Compute metrics\n",
    "    wer = jiwer.wer(label_str, pred_str)\n",
    "    cer = jiwer.cer(label_str, pred_str)\n",
    "\n",
    "    # Sentence Error Rate: fraction of sentences with at least 1 error\n",
    "    ser = sum(p != l for p, l in zip(pred_str, label_str)) / len(label_str)\n",
    "\n",
    "    return {\n",
    "        \"wer\": wer,\n",
    "        \"cer\": cer,\n",
    "        \"ser\": ser,\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_global_model(global_model, eval_dataset):\n",
    "    eval_args = TrainingArguments(\n",
    "        output_dir= model_save_path,\n",
    "        per_device_eval_batch_size=4,\n",
    "        report_to=\"none\",\n",
    "        do_train=False,\n",
    "        do_eval=True,\n",
    "        dataloader_drop_last=False,\n",
    "    )\n",
    "\n",
    "    eval_trainer = Trainer(\n",
    "        model=global_model,\n",
    "        args=eval_args,\n",
    "        tokenizer=processor.tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        eval_dataset=eval_dataset\n",
    "    )\n",
    "\n",
    "    results = eval_trainer.evaluate()\n",
    "    print(f\"Eval after round: WER={results['eval_wer']:.4f}, CER={results['eval_cer']:.4f}, SER={results['eval_ser']:.4f}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e2ff05-e5c1-4a33-b51a-6d45611b0535",
   "metadata": {},
   "source": [
    "#### FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3384ee0-ab79-4171-bdc5-b6c7e46b1ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Client 1 (data size: 2356)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='590' max='590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [590/590 01:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2336.855300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1118.408300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1095.097600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1116.550600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1080.965200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1097.838200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1055.103400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1108.191300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1142.380600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1068.973300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1019.178900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1111.494600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1093.251100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>987.799300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1065.935900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1016.535800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1096.734400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1067.071300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1115.526400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1050.436300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1098.382500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1028.167800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1011.561600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1088.777500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>998.978000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1015.249200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1018.133600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1070.243200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1115.242600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1003.751000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1053.273200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1032.855700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1032.053700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1043.624200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1032.460100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>970.671700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>958.604100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>897.030400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>876.525400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>894.171500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>814.558300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>831.976700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>776.141800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>804.319700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>789.955500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>710.025100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>751.811200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>735.668100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>722.020800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>726.370800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>720.210200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>707.188300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>679.589100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>705.896000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>651.305400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>675.456900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>653.512100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>688.542100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>630.360100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 (data size: 2276)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 01:33, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2174.067600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1143.092000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1103.048200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1087.894100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1072.468100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1048.405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1042.715600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1026.762300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1120.149900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1131.878800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1095.616600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1123.635200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1064.240300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1067.854500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1079.026400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1018.059500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1066.840200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1111.287500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1090.205500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1087.155400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1039.783000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1039.984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1044.586100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1043.609400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1070.956600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1030.803500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1078.832500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1031.320900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1037.161600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1012.139900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>969.557100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1121.846400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1135.533600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1021.997200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1003.748800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1059.078900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>942.616100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>920.846700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>932.955600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>874.898300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>925.319900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>865.186900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>882.319400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>797.924900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>791.898900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>832.544300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>774.205900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>813.932100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>802.061500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>796.567400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>766.807200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>783.581600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>731.285800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>741.655500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>750.539500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>724.848800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>678.416100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 3 (data size: 1676)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='420' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [420/420 01:08, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2181.730500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1122.076600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1075.514000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1030.184900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1049.924800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1063.416000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1126.634600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1065.287500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1107.185700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1075.057800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1060.773100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1051.791700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1105.121300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1013.871000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1078.741400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1084.877100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1076.023300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1023.554100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1087.376200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1079.639000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1006.846100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1060.663200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1057.650800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1024.758500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1093.187600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1068.651100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1043.993600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1068.962300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1131.423700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1055.230700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1032.088800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1069.564100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1129.794100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1078.698400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1061.014200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1035.983000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1025.357100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>984.256300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>954.554600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1006.570500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1058.386800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1014.126400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 4 (data size: 1170)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='294' max='294' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [294/294 00:51, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2257.661100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1116.535300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1018.676800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1047.238800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1085.776400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1052.597600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1068.381200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1013.510800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1031.369700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1007.415500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1092.427500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1099.185500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1026.727500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1055.317800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>999.619000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1124.305300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1069.739700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>958.600500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>947.601600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1103.085000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1069.549100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1052.341300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1077.724800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1037.990600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1111.488300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1029.089500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1043.864900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1035.713100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1069.878900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 5 (data size: 784)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='196' max='196' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [196/196 00:35, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2282.395100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1170.734800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1101.006500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1066.931300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1082.823600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1134.479900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1103.002800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1111.436400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1012.516000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1112.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1102.353700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1039.132000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1060.007700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1065.837600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1078.019900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1044.452400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1099.986600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1099.275300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1147.377900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1976712192.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=1.0000, CER=1.0000, SER=1.0000\n",
      "Round 2\n",
      "Client 1 (data size: 406)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='102' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:18, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1019.689100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>908.403600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>838.642100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>783.555700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>798.382800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>738.767500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>751.480300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>647.800200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>704.117500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>680.204600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 (data size: 1676)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='420' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [420/420 01:15, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>985.301900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>905.386300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>845.783500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>766.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>733.925300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>708.731800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>719.016700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>648.992800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>659.947500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>620.914600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>590.703900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>569.269700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>587.140700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>532.925800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>553.594200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>542.799400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>535.219500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>498.398000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>512.424200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>515.277300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>476.746200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>487.088100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>477.211300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>459.752900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>478.793700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>475.814300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>454.798500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>468.444500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>485.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>443.996100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>435.344500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>440.771200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>471.829000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>450.839700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>444.618700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>437.502900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>415.510400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>415.071100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>394.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>420.251000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>434.125600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>404.619000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 3 (data size: 1170)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='294' max='294' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [294/294 00:48, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1032.157500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>889.271900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>789.247000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>765.210900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>758.373000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>697.655000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>680.152900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>620.682900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>623.228500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>577.916500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>613.953200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>600.604500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>553.667100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>561.748600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>516.456900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>563.587700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>540.974500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>473.947900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>461.352800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>530.968600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>502.095400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>496.910600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>508.346700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>492.490800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>519.785300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>484.877400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>485.543600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>480.374000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>490.756200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 4 (data size: 917)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='230' max='230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [230/230 00:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>958.682400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>944.838400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>836.283200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>800.421500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>750.375800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>707.866100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>682.953900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>667.364400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>583.503100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>630.520300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>592.498000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>549.637900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>579.235700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>552.738100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>533.184700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>513.271300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>538.361500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>547.311000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>524.400900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>533.913800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>527.340800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>528.674000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>507.378500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 5 (data size: 2276)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 01:33, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1006.498900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>907.419900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>855.831500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>798.982900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>746.428700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>688.445300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>663.680600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>622.506300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>650.261800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>638.775200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>607.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>605.915200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>561.835300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>558.233300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>549.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>495.719100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>508.354500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>532.190400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>513.817000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>508.052000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>468.626500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>464.799700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>461.241200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>452.507300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>477.313200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>444.919300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>451.707800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>431.531400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>429.370800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>411.071500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>398.223400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>441.155600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>457.804900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>413.952900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>401.930200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>433.901900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>392.350100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>396.015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>411.635700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>390.741700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>426.951900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>405.558700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>404.636400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>377.926600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>389.450600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>398.704800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>380.063900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>396.793500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>396.784400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>403.383500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>388.764000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>402.720500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>374.942200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>385.201900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>389.590100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>381.324800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>346.005700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_661558/1976712192.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=0.8652, CER=0.3637, SER=1.0000\n",
      "Round 3\n",
      "Client 1 (data size: 406)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='102' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:16, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>504.087000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>483.323800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>460.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>438.230100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>467.124800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>426.243100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>441.795900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>388.969400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>423.944800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>412.883600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 (data size: 1676)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='420' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [420/420 01:08, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>484.238400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>476.901200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>462.610800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>436.356900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>433.786900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>441.323900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>467.713500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>422.309000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>439.152600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>426.459200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>411.485800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>402.065900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>418.155700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>387.316200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>404.772700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>399.292400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>398.029600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>368.496500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>381.401700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>385.282700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>362.656600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>363.504000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>356.191000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>346.555300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>359.798800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>366.696300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>347.631700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>357.190500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>376.375600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>338.057900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>334.682900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>337.578300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>367.289500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>346.627600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>342.976300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>341.681600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>320.568600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>325.181900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>307.909500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>327.730200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>342.007800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>312.322200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 3 (data size: 1170)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='294' max='294' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [294/294 00:48, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>519.041300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>472.059800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>446.799600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>451.320200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>477.238800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>440.091900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>444.500700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>408.685300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>422.858600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>389.953800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>422.097900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>420.416700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>389.339800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>406.413800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>371.500100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>400.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>385.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>341.461400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>331.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>386.647300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>361.685800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>363.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>375.129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>367.343900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>384.259400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>360.988900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>360.931900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>356.292100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>366.285500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 4 (data size: 917)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='230' max='230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [230/230 00:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>483.235300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>498.287500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>460.779800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>465.820600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>452.799400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>437.412900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>441.562200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>436.292100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>392.581800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>430.137600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>404.503300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>377.018600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>395.736100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>380.808400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>367.337100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>353.559000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>377.613800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>385.619300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>373.493700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>383.605600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>374.854200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>377.541800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>360.307000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 5 (data size: 2276)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 01:33, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>498.444200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>479.919200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>480.591500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>467.645800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>453.189500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>428.989600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>430.267100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>413.474600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>441.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>438.378000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>427.425100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>428.446500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>400.292100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>409.019400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>405.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>365.056100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>380.138500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>400.009800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>389.952100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>391.058200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>358.630900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>359.139300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>359.620600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>351.415800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>379.847600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>348.590100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>359.887900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>344.658500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>340.139500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>325.459800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>314.087300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>346.802100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>365.570900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>331.715100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>321.832800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>346.645200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>313.152800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>318.676600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>333.916700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>316.496800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>347.182500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>328.405400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>329.962400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>305.974200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>320.193800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>325.843700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>308.628400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>325.002800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>321.977400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>328.894200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>316.832000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>330.648700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>305.991000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>318.542300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>318.876400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>313.899200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>283.154200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_661558/1976712192.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=0.7712, CER=0.2724, SER=1.0000\n",
      "Round 4\n",
      "Client 1 (data size: 406)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='102' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:16, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>377.563600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>375.384100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>358.571400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>347.120500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>370.030300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>333.725600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>344.289500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>307.668200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>334.181000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>326.197300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 (data size: 1676)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='420' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [420/420 01:08, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>361.647900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>369.318800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>364.617600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>343.777200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>345.531500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>359.027200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>385.030900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>341.604400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>359.170800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>354.411600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>342.524300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>337.684600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>350.602000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>327.816900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>342.835400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>339.644500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>339.710900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>315.098100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>325.041600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>331.777100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>312.999800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>309.670300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>301.485900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>293.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>306.217800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>315.522900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>296.918300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>306.622000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>323.644200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>288.761700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>288.169600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>290.355000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>318.832800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>297.906700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>296.008600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>295.846000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>275.748300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>282.545200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>268.324200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>285.050500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>299.621700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>269.927200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 3 (data size: 1170)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='294' max='294' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [294/294 00:47, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>388.520200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>364.681800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>351.300700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>358.706800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>386.945900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>358.481100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>364.288400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>333.752400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>351.129100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>320.065200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>350.679000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>350.458400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>325.293400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>342.248700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>312.737600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>333.209500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>319.835000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>284.753400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>275.742000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>324.982400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>301.229900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>306.945100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>317.639700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>311.562900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>325.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>305.057900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>305.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>301.685800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>309.484600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 4 (data size: 917)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='230' max='230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [230/230 00:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>364.404200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>385.499400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>360.781600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>365.706700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>360.314200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>350.133200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>360.680900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>355.871100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>322.066700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>356.436100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>334.848500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>311.058700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>324.910200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>310.354400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>301.070500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>290.796100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>312.574500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>318.291000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>309.123600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>321.060600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>312.339000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>313.985500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>298.224900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 5 (data size: 2276)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 01:33, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>374.106900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>372.741000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>373.068600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>367.402700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>362.675800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>343.925300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>351.459700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>341.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>364.103600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>364.923900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>357.261600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>358.788800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>335.238500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>346.653300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>345.396700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>311.686800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>327.178500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>342.935000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>334.715500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>337.717700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>309.758800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>310.124200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>312.827600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>303.615500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>334.180700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>301.378500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>315.747900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>302.232500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>296.938700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>281.738400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>272.738300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>298.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>318.268800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>288.766600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>280.033500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>302.168500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>271.359400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>279.050500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>293.543400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>277.380700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>305.787100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>287.379300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>290.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>268.407700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>282.601700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>286.863800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>271.466200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>288.239100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>283.027800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>289.833900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>279.020700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>292.863100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>268.915800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>282.833000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>281.139500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>277.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>250.199200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_661558/1976712192.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:25]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=0.7052, CER=0.2390, SER=1.0000\n",
      "Round 5\n",
      "Client 1 (data size: 406)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='102' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:16, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>317.029200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>324.496700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>312.173400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>303.169700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>323.118400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>286.815200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>293.682400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>265.610900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>290.079800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>282.347100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 (data size: 1676)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='420' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [420/420 01:08, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>303.764200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>318.121600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>316.470500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>297.971300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>301.612600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>314.555300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>338.894200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>297.511600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>315.563400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>312.278300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>303.584300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>301.861700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>313.047800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>293.791400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>305.998900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>302.749200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>303.240900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>283.230400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>291.397100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>300.299300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>281.892100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>276.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>266.908200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>260.169300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>273.714700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>283.057400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>264.505500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>274.390900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>289.536500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>257.401600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>259.093500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>259.484800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>287.115900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>267.102200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>266.497400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>266.463200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>247.386300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>254.745900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>243.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>258.493000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>272.753100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>242.994000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 3 (data size: 1170)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='294' max='294' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [294/294 00:48, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>325.737400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>313.744500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>302.256600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>313.301400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>339.590600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>315.193600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>321.313300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>292.573500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>312.042100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>281.701500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>309.853500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>311.788400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>287.780700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>304.640300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>278.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>293.229000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>280.662200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>251.182500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>242.599700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>287.696100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>265.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>273.311900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>283.152200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>277.677600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>290.052900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>271.791300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>272.105200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>270.380800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>275.207300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 4 (data size: 917)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='230' max='230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [230/230 00:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>306.944900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>331.202300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>312.553700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>317.149100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>313.596700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>305.450100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>318.067000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>313.471400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>283.165100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>316.185300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>297.099000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>274.044400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>283.512100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>270.913700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>263.180900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>255.994400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>274.978000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>281.361500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>272.769700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>285.918100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>275.919300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>277.727300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>263.596000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 5 (data size: 2276)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 01:33, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>315.229700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>320.643200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>322.500200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>318.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>315.665000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>298.899200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>307.509900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>300.377100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>319.724500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>323.281400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>315.550900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>318.904400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>297.809400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>310.999500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>310.059000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>278.265700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>293.492200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>308.535100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>300.191000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>303.600400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>277.989100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>278.677800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>283.688700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>273.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>304.483300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>271.038300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>287.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>275.005400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>267.809100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>253.263600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>245.107500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>266.951700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>286.213400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>261.188900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>252.626900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>272.461000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>244.073800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>252.540700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>266.803100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>250.744700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>278.260500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>259.990900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>264.832600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>243.880700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>257.153500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>260.469900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>246.572900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>263.183300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>257.060200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>264.174400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>254.100500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>267.024800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>244.278600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>258.405600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>256.553900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>253.982800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>228.535300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_661558/1976712192.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=0.6646, CER=0.2204, SER=1.0000\n",
      "Round 6\n",
      "Client 1 (data size: 406)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='102' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:16, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>276.389200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>290.375100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>282.153200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>274.803100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>293.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>255.819200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>260.984700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>237.942700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>261.932900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>253.640900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 (data size: 1676)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='420' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [420/420 01:08, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>264.095800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>284.581100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>284.173400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>267.332400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>271.607800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>284.414000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>307.305900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>268.419200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>285.707500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>282.273400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>276.868900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>276.563300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>285.950300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>268.932000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>279.489400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>275.580900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>277.419100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>260.088600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>267.183500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>277.488200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>259.571000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>251.339100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>241.859500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>235.464800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>250.171400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>258.804500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>240.472000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>250.090800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>264.483400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>234.457200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>237.542000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>236.749800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>263.053300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>244.635700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>244.494500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>244.643300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>226.886000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>233.861000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>224.210200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>238.877000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>252.791200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>223.625600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 3 (data size: 1170)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='294' max='294' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [294/294 00:48, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>284.881300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>280.534400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>269.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>283.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>308.305400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>285.140300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>291.790900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>264.140100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>284.202400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>255.544200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>281.623500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>285.695400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>262.613400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>279.038100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>252.771000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>264.672200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>252.990800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>226.572500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>219.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>260.646600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>240.407600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>249.600300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>257.349300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>253.010400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>264.583500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>247.987600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>248.931800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>247.987300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>250.940000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 4 (data size: 917)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='230' max='230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [230/230 00:38, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>268.676700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>295.913600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>279.404000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>285.855600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>282.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>276.312000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>289.618300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>284.711400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>257.196600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>288.832200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>271.235700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>248.786200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>254.793900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>243.994900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>236.290700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>231.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>248.539300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>256.117800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>247.579400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>262.187700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>251.034200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>252.394000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>239.871200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 5 (data size: 2276)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 01:35, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>277.056500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>286.564800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>290.267700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>287.265000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>284.899700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>268.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>276.571300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>272.536800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>289.642100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>294.767900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>287.225800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>291.189500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>270.889600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>286.131400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>284.481300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>254.247900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>268.896300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>284.234300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>274.675100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>278.854500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>255.015800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>255.519500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>262.429600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>251.181400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>282.558400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>249.340600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>266.074900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>255.043500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>246.463800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>231.951300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>224.268700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>242.918800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>261.379300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>239.784300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>231.454700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>249.612300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>224.198100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>232.085400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>245.826700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>230.616800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>257.926100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>239.574900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>245.435000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>225.714200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>237.937600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>240.464800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>227.713300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>243.840900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>237.694800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>244.991100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>236.115500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>247.527500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>225.412400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>240.331600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>238.483200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>236.400400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>212.557900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_661558/1976712192.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=0.6338, CER=0.2076, SER=0.9996\n",
      "Round 7\n",
      "Client 1 (data size: 406)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='102' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:16, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>244.869600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>264.597600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>259.443100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>254.639300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>270.830900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>232.891000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>237.092200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>217.132400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>240.538400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>232.468500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 (data size: 1676)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='420' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [420/420 01:10, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>232.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>259.502000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>259.910100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>243.888800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>248.514200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>261.525300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>283.694300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>246.229200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>263.170500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>259.951400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>255.668600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>256.820100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>264.662200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>249.889600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>258.240100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>254.817100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>257.482100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>241.466400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>248.341100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>259.256500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>242.151200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>231.387100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>221.954500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>215.894600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>231.164800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>239.593900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>221.432400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>230.738800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>245.232400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>216.416900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>220.620800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>218.971400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>244.305900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>227.301300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>227.042100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>227.883600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>211.224000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>217.846800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>209.690900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>223.195000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>237.575400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>208.770300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 3 (data size: 1170)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='294' max='294' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [294/294 00:48, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>254.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>255.746700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>245.067700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>259.845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>283.756900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>261.840800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>269.053300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>241.888800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>262.854900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>235.623100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>260.214500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>265.446000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>243.366000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>259.733500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>232.869700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>242.556700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>231.769600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>207.397400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>201.032300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>239.344700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>221.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>231.257000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>237.404200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>233.990600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>244.652500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>230.259800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>231.182400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>230.534600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>232.751800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 4 (data size: 917)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='230' max='230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [230/230 00:38, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>239.384300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>269.306800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>254.708100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>262.261200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>257.664100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>254.336500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>267.395500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>263.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>237.602700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>267.603300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>251.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>229.748200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>233.278600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>222.855300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>215.497700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>212.029600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>228.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>236.821700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>228.183200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>243.910200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>231.916100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>233.487500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>221.958900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 5 (data size: 2276)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 01:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>247.484400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>260.717300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>265.409700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>263.691400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>261.368300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>244.831800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>252.296100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>251.195800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>265.993400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>272.085200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>264.993100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>269.256400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>249.816000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>266.139600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>264.118000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>235.119900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>249.517300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>265.563100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>254.812000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>259.501400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>237.225100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>237.395300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>245.160500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>233.762700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>265.326000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>232.487900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>249.232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>238.878100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>229.322200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>214.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>207.614800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>223.210800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>241.089900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>222.790900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>214.388900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>231.546800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>208.333400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>215.590400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>228.724200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>214.095800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>241.487300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>223.012400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>230.033900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>211.254200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>222.054000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>224.449600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>212.175700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>228.443000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>222.051200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>230.048900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>221.614100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>232.351700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>210.337600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>225.832100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>224.221500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>223.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>199.728200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_661558/1976712192.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=0.6113, CER=0.1977, SER=0.9996\n",
      "Round 8\n",
      "Client 1 (data size: 406)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='102' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:16, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>218.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>243.119900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>240.797900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>238.354900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>252.691200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>214.707700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>217.595100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>200.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>222.406700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>215.772600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 (data size: 1676)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='420' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [420/420 01:09, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>206.996800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>238.923100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>240.667700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>225.022700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>229.856100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>242.856300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>263.809300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>227.336200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>244.704300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>241.623300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>237.995100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>240.319100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>247.113500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>234.119100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>240.704000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>238.482900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>241.339900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>226.121800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>233.394100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>244.210500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>227.890700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>215.107300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>205.657300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>199.793200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>215.650100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>223.639900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>205.694800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>214.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>229.599200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>202.157100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>206.848600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>204.986700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>228.998900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>213.305400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>212.694300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>214.181900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>198.451600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>204.923600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>197.954500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>210.433800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>225.646900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>196.930900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 3 (data size: 1170)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='294' max='294' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [294/294 00:48, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>228.085200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>234.373900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>224.416300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>240.661400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>261.897400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>243.398000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>250.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>223.244800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>245.256200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>219.404400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>242.507300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>248.585900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>227.780300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>243.910200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>216.647200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>223.474100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>213.935300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>191.920200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>186.132900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>222.052300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>205.350900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>216.803900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>221.376800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>218.519300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>228.993400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>215.618200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>217.031100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>217.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>218.081300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 4 (data size: 917)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='230' max='230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [230/230 00:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>214.500700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>247.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>235.058300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>243.574600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>238.034000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>236.776700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>249.071800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>245.193200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>221.753200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>250.271000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>235.637800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>213.883300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>215.630700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>205.808500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>198.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>196.357400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>211.685100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>220.952100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>212.407300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>229.492600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>217.133700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>218.596000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>207.714600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 5 (data size: 2276)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 01:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>222.761800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>239.419000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>244.876100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>244.324500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>241.620800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>225.272500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>232.508800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>233.538600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>247.300700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>252.642700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>246.714800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>250.374900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>232.493200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>249.962100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>246.707200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>219.649500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>233.304300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>250.256200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>238.744400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>243.154800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>222.525500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>222.278000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>230.610900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>219.198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>250.692900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>218.575700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>234.921100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>225.141600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>215.148900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>199.683200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>193.377600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>207.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>223.890600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>208.602400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>200.471800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>216.367500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>194.839800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>202.219900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>214.501300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>199.894900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>227.714100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>209.230900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>217.017100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>198.524400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>208.955900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>210.901100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>199.286700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>215.498600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>209.032300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>217.554400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>209.573000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>220.022600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>197.853300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>213.725200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>212.336500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>211.669800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>189.207400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_661558/1976712192.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=0.5941, CER=0.1907, SER=0.9996\n",
      "Round 9\n",
      "Client 1 (data size: 406)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='102' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:16, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>195.774100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>224.694600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>225.207500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>225.052300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>238.154200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>199.762700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>201.542100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>186.721800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>208.343600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>202.820200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 (data size: 1676)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='420' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [420/420 01:09, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>184.644900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>220.779000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>224.250900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>208.423600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>214.163900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>226.480300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>246.510500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>211.030200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>229.060900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>225.892900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>222.537200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>226.079200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>232.556000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>220.391700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>225.750100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>224.593800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>227.557400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>212.860300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>220.825400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>231.412500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>215.864400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>200.731200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>191.639400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>185.958100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>202.255700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>209.598700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>192.190600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>201.362500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>216.295000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>190.206900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>194.775200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>193.248700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>216.105900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>201.457100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>200.738300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>202.694200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>188.008500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>193.909700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>188.483300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>199.883300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>215.340100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>187.084500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 3 (data size: 1170)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='294' max='294' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [294/294 00:48, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>205.082300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>216.904900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>206.918200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>224.036400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>243.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>228.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>234.769300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>207.831700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>230.849000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>205.742800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>227.167700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>234.774700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>214.183500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>230.414200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>203.060700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>206.809800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>198.969400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>179.101600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>173.598500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>207.460200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>192.138200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>204.576300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>208.199800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>205.977400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>215.844000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>203.358100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>205.188300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>206.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>205.889000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 4 (data size: 917)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='230' max='230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [230/230 00:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>193.295600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>228.391900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>218.570100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>228.069500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>221.775500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>222.078700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>233.472800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>230.297300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>208.356000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>235.878100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>222.370500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>200.534400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>200.931500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>191.281600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>183.863700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>183.169500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>198.124100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>207.719200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>199.306500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>217.519900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>205.047700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>206.652300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>196.339800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 5 (data size: 2276)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 01:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>201.307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>220.586700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>227.284100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>227.173900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>224.775500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>208.335300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>215.468500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>218.375300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>231.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>235.410400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>230.039300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>233.338300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>217.181700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>235.743500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>231.673800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>205.915700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>218.645800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>236.259900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>224.822600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>228.522300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>209.871900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>209.114300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>218.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>206.527300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>238.056200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>206.808900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>222.474400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>213.229500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>202.720400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>186.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>180.662600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>193.523200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>209.064600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>196.108600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>188.369400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>203.029900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>183.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>191.046400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>202.166500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>187.797100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>216.181200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>197.897700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>205.683600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>187.656500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>197.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>199.389900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>188.423000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>204.788400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>197.975100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>207.080300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>199.441400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>210.105400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>187.724200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>203.457800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>202.490700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>202.709900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>180.207100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_661558/1976712192.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=0.5790, CER=0.1849, SER=0.9996\n",
      "Round 10\n",
      "Client 1 (data size: 406)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='102' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:16, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>175.583800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>208.505200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>212.085900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>213.110600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>225.923900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>186.669900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>188.789500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>175.891500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>197.077400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>192.155200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 (data size: 1676)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='420' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [420/420 01:09, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>164.501400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>204.354600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>209.132600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>193.508200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>200.015700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>211.984400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>231.188700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>197.070700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>215.102900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>211.832400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>208.788700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>213.215900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>219.737100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>207.973400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>212.870500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>212.327400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>215.486600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>201.090700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>209.898900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>220.198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>205.286400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>187.873600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>179.058000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>173.803900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>190.260200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>197.118600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>180.489900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>189.858400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>204.653300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>179.987500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>184.161500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>182.755500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>205.057500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>191.142900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>190.481900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>192.843300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>178.875300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>184.239800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>180.415700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>190.783300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>206.503700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>178.443200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 3 (data size: 1170)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='294' max='294' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [294/294 00:48, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>185.154600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>202.478200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>191.752200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>209.540900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>226.565300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>214.318200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>221.149400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>194.314600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>218.390000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>193.789000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>213.773400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>222.936200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>202.508300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>218.640500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>191.216100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>192.577800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>185.731200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>168.076800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>162.743800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>194.594300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>181.089200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>193.802700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>196.895400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>194.745500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>204.783900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>192.961800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>195.101400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>196.909900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>195.925100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 4 (data size: 917)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='230' max='230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [230/230 00:38, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>173.901300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>211.927000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>203.858500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>214.701800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>207.922700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>209.301000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>220.225500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>217.102600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>196.673900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>223.707800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>210.566700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>188.853700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>188.113500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>178.591400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>171.575800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>171.800500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>186.472600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>196.853100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>188.611600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>207.234200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>194.701900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>196.483200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>187.093700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 5 (data size: 2276)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_661558/1486125750.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 01:35, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>182.266400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>203.630400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>212.142900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>212.085900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>210.050700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>193.495700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>200.593300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>204.592000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>218.073800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>220.158300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>214.746500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>217.929900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>203.362700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>223.114900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>218.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>193.749700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>205.502600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>223.350600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>212.121900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>215.458900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>198.566900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>197.260100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>206.547300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>195.518400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>227.009400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>196.386800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>211.664100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>202.733700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>191.681000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>174.701700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>169.484300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>181.453200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>195.951500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>185.090600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>177.264900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>191.457600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>172.998700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>181.011100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>190.951900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>177.551000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>205.881200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>188.016400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>195.426800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>178.284500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>187.674800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>189.471000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>179.309600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>195.417700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>188.259900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>198.122800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>190.745900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>201.280100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>179.178700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>194.954300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>194.329500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>194.930200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>172.342600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_661558/1976712192.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=0.5669, CER=0.1803, SER=0.9996\n"
     ]
    }
   ],
   "source": [
    "global_model = deepcopy(base_model)\n",
    "round_metrics = []\n",
    "\n",
    "for round_num in range(10):\n",
    "    print(f\"Round {round_num + 1}\")\n",
    "    selected_clients = random.sample(client_datasets, k=5)\n",
    "    weights = []\n",
    "    client_losses = []\n",
    "\n",
    "    for i, client_data in enumerate(selected_clients):\n",
    "        print(f\"Client {i+1} (data size: {len(client_data)})\")\n",
    "        local_model = copy.deepcopy(global_model)\n",
    "        state, train_metrics = local_finetune(\n",
    "            local_model,\n",
    "            client_data,\n",
    "            processor,\n",
    "            data_collator,\n",
    "            compute_metrics,\n",
    "            model_save_path, \n",
    "        )\n",
    "        weights.append(state)\n",
    "        client_losses.append(train_metrics[\"train_loss\"])\n",
    "\n",
    "    # FedAvg\n",
    "    avg_weights = fed_avg(weights)\n",
    "    global_model.load_state_dict(avg_weights)\n",
    "\n",
    "    # Save the global model\n",
    "    round_model_dir = os.path.join(model_save_path, f\"round{round_num+1}_global_model\")\n",
    "    os.makedirs(round_model_dir, exist_ok=True)\n",
    "    global_model.save_pretrained(round_model_dir)\n",
    "\n",
    "    # Evaluate global model and log metrics\n",
    "    eval_metrics = evaluate_global_model(global_model, eval_dataset)\n",
    "\n",
    "    round_metrics.append({\n",
    "        \"round\": round_num + 1,\n",
    "        \"train_loss\": sum(client_losses) / len(client_losses),\n",
    "        \"train_steps\": train_metrics[\"train_steps\"],\n",
    "        \"eval_loss\": eval_metrics.get(\"eval_loss\"),\n",
    "        \"eval_wer\": eval_metrics.get(\"eval_wer\"),\n",
    "        \"eval_cer\": eval_metrics.get(\"eval_cer\"),\n",
    "        \"eval_ser\": eval_metrics.get(\"eval_ser\"),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4817032f-e83a-4aef-a012-75ae69e51de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save final model and processor\n",
    "final_model_dir = os.path.join(model_save_path, \"fedavg_distilhubert_asr\")\n",
    "global_model.save_pretrained(final_model_dir)\n",
    "processor.save_pretrained(final_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7fec08e-c2ed-4a4a-93bb-107902d13fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "metrics_df = pd.DataFrame(round_metrics)\n",
    "metrics_df.to_csv(os.path.join(model_save_path, \"FedAvg_round_metrics.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df303360-e0b3-40f0-ac2c-6e1abb41f7a0",
   "metadata": {},
   "source": [
    "#### Reload & plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad457806-1268-4d2b-8157-a0cd2fe62207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/scratch/pippalin2/jupyter/GMM-DistilHuBERT/FL_script/FedAvg_checkpoints/FedAvg_round_metrics.csv\")\n",
    "plt.plot(df[\"round\"], df[\"eval_wer\"], label=\"WER\")\n",
    "plt.plot(df[\"round\"], df[\"eval_cer\"], label=\"CER\")\n",
    "plt.plot(df[\"round\"], df[\"eval_ser\"], label=\"SER\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Evaluation Metrics per Round\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c25ef6a7-05e8-4025-b190-61b338b77e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df[\"round\"], df[\"train_loss\"], color='black', label=\"train loss\")\n",
    "plt.plot(df[\"round\"], df[\"eval_loss\"], color='red', label=\"eval loss\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss per Round\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
