{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e998eaf8-5779-4744-931c-fd950d7b9d31",
   "metadata": {},
   "source": [
    "### Federated Fine-tuning for ASR\n",
    "* Centralized: You fine-tune DistilHuBERT for downstream ASR tasks.\n",
    "* FL: Simulate a federated ASR learning scenario where multiple clients (speakers) fine-tune a shared model on local speech data using FedAvg/FedOpt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19e17708-97c4-46cc-898d-d861af81fc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddaa46a2-3144-4aa0-a272-c6642604ec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "from datasets import load_from_disk\n",
    "from transformers import (\n",
    "    AutoProcessor,\n",
    "    AutoModelForCTC,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from typing import List, Dict\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import random\n",
    "import jiwer\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7964eb38-e7d0-449f-8ffe-461f24b0d74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a5ff36462a4afcb87c3686a710234d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_from_disk(\"/scratch/pippalin2/jupyter/GMM-DistilHuBERT/processed_dataset\")\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = dataset[\"train\"]\n",
    "eval_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06c2ee39-91c7-4088-9703-b19ab2c6cdeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_values', 'labels'],\n",
       "    num_rows: 25670\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97abe893-61b2-492e-b44c-66f63cff3928",
   "metadata": {},
   "source": [
    "#### Simulating FL setting: clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0cace8a-ae84-416d-b339-d668d90fda47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_clients_nonuniform(dataset, num_clients, min_frac, max_frac):\n",
    "    size = len(dataset)\n",
    "\n",
    "    proportions = np.random.uniform(min_frac, max_frac, size=num_clients)\n",
    "    proportions = proportions / proportions.sum()\n",
    "    sizes = (proportions * size).astype(int)\n",
    "\n",
    "    # Ensure total size matches\n",
    "    diff = size - sizes.sum()\n",
    "    sizes[0] += diff\n",
    "\n",
    "    # Client splits\n",
    "    indices = np.arange(size)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    client_datasets = []\n",
    "    start = 0\n",
    "    for s in sizes:\n",
    "        end = start + s\n",
    "        client_datasets.append(dataset.select(indices[start:end].tolist()))\n",
    "        start = end\n",
    "\n",
    "    return client_datasets\n",
    "client_datasets = split_into_clients_nonuniform(train_dataset, num_clients=20, min_frac=0.01, max_frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "547e725f-9e29-4814-ab4d-efb7705ab427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of HubertForCTC were not initialized from the model checkpoint at ntu-spml/distilhubert and are newly initialized: ['lm_head.bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"/scratch/pippalin2/jupyter/GMM-DistilHuBERT/processor\")\n",
    "base_model = AutoModelForCTC.from_pretrained(\"ntu-spml/distilhubert\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "410b7a2b-edf1-40e8-99dc-7a3bdfbc0894",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCollatorCTCWithPadding:\n",
    "    def __init__(self, processor, padding=True):\n",
    "        self.processor = processor\n",
    "        self.padding = padding\n",
    "\n",
    "    def __call__(self, features: List[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_features = [{\"input_values\": f[\"input_values\"]} for f in features]\n",
    "        label_features = [{\"input_ids\": f[\"labels\"]} for f in features]\n",
    "\n",
    "        batch = self.processor.feature_extractor.pad(input_features, padding=self.padding, return_tensors=\"pt\")\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, padding=self.padding, return_tensors=\"pt\")\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorCTCWithPadding(processor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abe1c812-70dd-4721-9048-c0e93ffd30dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_finetune(model, dataset, processor, collator, compute_metrics, output_dir):\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./FedAvg_checkpoints\",\n",
    "        per_device_train_batch_size=2,\n",
    "        eval_strategy=\"no\",\n",
    "        num_train_epochs=2,\n",
    "        eval_steps=400,\n",
    "        logging_steps=10,\n",
    "        save_steps=500,\n",
    "        learning_rate=1e-4,\n",
    "        fp16=True,\n",
    "        resume_from_checkpoint=False,\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset,\n",
    "        tokenizer=processor,\n",
    "        data_collator=collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    train_output = trainer.train()\n",
    "    metrics = {\n",
    "    \"train_loss\": train_output.training_loss,\n",
    "    \"train_steps\": training_args.max_steps if training_args.max_steps else None,\n",
    "    }\n",
    "    return model.state_dict(), metrics\n",
    "\n",
    "def fed_avg(state_dicts: List[Dict]):\n",
    "    avg_dict = copy.deepcopy(state_dicts[0])\n",
    "    for key in avg_dict:\n",
    "        for i in range(1, len(state_dicts)):\n",
    "            avg_dict[key] += state_dicts[i][key]\n",
    "        avg_dict[key] = avg_dict[key] / len(state_dicts)\n",
    "    return avg_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec61d43c-3f2e-4b22-85b6-355f52d4ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = jiwer.Compose([\n",
    "    jiwer.ToLowerCase(),\n",
    "    jiwer.RemovePunctuation(),\n",
    "    jiwer.RemoveMultipleSpaces(),\n",
    "    jiwer.Strip(),\n",
    "])\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = torch.argmax(torch.tensor(pred_logits), dim=-1)\n",
    "\n",
    "    # Decode predictions\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "\n",
    "    # Decode references\n",
    "    label_ids = pred.label_ids\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    label_str = processor.batch_decode(label_ids, group_tokens=False)\n",
    "\n",
    "    # Normalize\n",
    "    pred_str = [transform(p) for p in pred_str]\n",
    "    label_str = [transform(l) for l in label_str]\n",
    "\n",
    "    # Compute metrics\n",
    "    wer = jiwer.wer(label_str, pred_str)\n",
    "    cer = jiwer.cer(label_str, pred_str)\n",
    "\n",
    "    # Sentence Error Rate: fraction of sentences with at least 1 error\n",
    "    ser = sum(p != l for p, l in zip(pred_str, label_str)) / len(label_str)\n",
    "\n",
    "    return {\n",
    "        \"wer\": wer,\n",
    "        \"cer\": cer,\n",
    "        \"ser\": ser,\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_global_model(global_model, eval_dataset):\n",
    "    eval_args = TrainingArguments(\n",
    "        output_dir=\"./FedAvg_checkpoints/eval_temp\",\n",
    "        per_device_eval_batch_size=4,\n",
    "        report_to=\"none\",\n",
    "        do_train=False,\n",
    "        do_eval=True,\n",
    "        dataloader_drop_last=False,\n",
    "    )\n",
    "\n",
    "    eval_trainer = Trainer(\n",
    "        model=global_model,\n",
    "        args=eval_args,\n",
    "        tokenizer=processor.tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        eval_dataset=eval_dataset\n",
    "    )\n",
    "\n",
    "    results = eval_trainer.evaluate()\n",
    "    print(f\"Eval after round: WER={results['eval_wer']:.4f}, CER={results['eval_cer']:.4f}, SER={results['eval_ser']:.4f}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c477f12c-3af3-4b5e-9c8c-2fff59322ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Client 1 (data size: 309)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='78' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [78/78 00:13, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2218.662300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1182.677600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1109.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1096.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1113.170400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1066.201800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1081.207800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 (data size: 834)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='210' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [210/210 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2100.705100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1087.940500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1059.045300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1162.771400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1039.536400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1007.393600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1081.531000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1033.104400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1094.177700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1117.028700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>998.122000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>979.978800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1090.670500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1096.506100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1042.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1056.683300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1059.364400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1047.055500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1035.385400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1111.762700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>959.215600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 3 (data size: 2105)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='528' max='528' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [528/528 01:26, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2201.104100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1150.742600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1166.375900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1094.314000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1111.500800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1059.819200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1109.354800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1075.791000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1003.945000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1002.100200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1005.184300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1126.463300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1045.086900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1078.097000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1006.251600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1020.853800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1075.811300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1075.348500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1036.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1001.715300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1055.913600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>982.266100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1111.890800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1101.543800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1042.573600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1036.109200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>910.130800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>960.911400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>989.415600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>963.924900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>943.005700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>937.004800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>949.183500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>835.137800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>816.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>814.894300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>783.619000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>756.723400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>758.277200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>730.672100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>701.130700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>724.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>686.738500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>695.367200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>708.245200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>596.671400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>690.569000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>677.268700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>636.211700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>663.844500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>657.233000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>638.723100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 4 (data size: 1804)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='452' max='452' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [452/452 01:13, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2211.679100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1176.314900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1058.910300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1024.782200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1118.320300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1031.918900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1018.212600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>970.057700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1018.020700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1076.522100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1011.304100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1053.199000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1105.613000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1034.868600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>995.614600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1030.867800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1046.860200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1051.133600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1114.789300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1124.295500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1041.492700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1022.263400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>916.162000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1027.506200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1039.926300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1064.842300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1026.223000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1029.488300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1130.181400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1075.105400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>944.427700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>986.439500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1036.079800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>943.176900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>912.486500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>898.226300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>921.468300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>876.714300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>885.801400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>880.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>788.243000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>840.686100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>824.751600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>879.461100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>839.769500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 5 (data size: 313)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 00:12, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2268.843200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1164.797500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1070.936800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1000.446800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1107.101300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1032.597100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1056.641900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>996.150100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/1516574793.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=1.0000, CER=1.0000, SER=1.0000\n",
      "Round 2\n",
      "Client 1 (data size: 1004)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='252' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [252/252 00:41, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1102.559100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1039.106100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1030.384000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>877.309900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>859.567500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>806.963300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>771.173500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>752.814500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>671.036600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>645.816700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>647.273300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>615.523100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>533.694800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>573.202200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>555.331900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>588.558900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>570.094900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>565.396000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>551.954900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>541.887500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>550.319100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>537.740200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>519.823600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>543.330300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>515.318600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 (data size: 1077)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:44, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1031.096600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>988.471600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>924.148300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>868.515800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>803.369600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>749.401900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>782.569300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>692.837200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>651.098200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>651.055600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>612.936600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>631.093000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>561.082900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>570.228700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>538.183700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>568.688800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>598.074300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>500.718000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>538.531200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>545.093400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>501.371900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>504.101800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>502.009100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>497.235700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>479.074100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>482.512500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>549.108800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 3 (data size: 1029)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='258' max='258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [258/258 00:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1036.174300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1091.899900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>952.468000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>919.883900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>889.386300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>756.978300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>809.946800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>678.153700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>691.594900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>637.700700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>657.570900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>610.428300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>535.405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>595.358400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>584.787800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>539.881200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>540.689400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>526.646800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>527.870500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>508.695900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>541.574100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>538.281500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>529.219100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>510.026800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>528.584200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 4 (data size: 578)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [146/146 00:23, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1076.241800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1038.237200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>966.694000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>917.754700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>877.849600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>834.708300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>771.713000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>705.474800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>710.024300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>681.915700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>661.651800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>661.002100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>686.559700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>664.568700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 5 (data size: 2309)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='578' max='578' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [578/578 01:35, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1058.713100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1002.539800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>900.498200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>898.425100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>799.334200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>768.498700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>706.342300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>671.764800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>614.153400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>659.952300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>595.411300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>560.266100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>594.379200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>557.661500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>571.666200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>515.553900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>537.914400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>543.350300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>526.708800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>502.431800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>490.375500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>473.811700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>474.780700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>490.692300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>451.272100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>461.340600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>480.195000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>439.714900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>443.914400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>405.119700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>401.937000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>411.594300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>429.798600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>413.812200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>445.210400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>415.523800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>414.181700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>418.526900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>405.097100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>410.733900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>380.252500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>409.712200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>412.233600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>384.482100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>393.882600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>364.402200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>404.323200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>388.029400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>420.448200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>408.757400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>394.103000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>397.154200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>365.056200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>386.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>416.884400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>384.063000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>381.926600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_418300/1516574793.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=0.8821, CER=0.3770, SER=1.0000\n",
      "Round 3\n",
      "Client 1 (data size: 1004)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='252' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [252/252 00:41, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>532.306700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>508.593300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>525.476600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>459.685000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>466.188500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>465.007400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>462.801300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>470.875300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>423.817200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>420.769300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>431.942900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>420.296600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>365.899400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>383.312100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>381.651600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>407.598300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>390.129800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>397.478200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>390.061700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>385.327700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>386.769300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>372.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>367.102500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>391.046700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>366.893300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 (data size: 1077)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:44, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>510.189300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>495.435700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>478.833800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>478.865100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>454.171500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>441.675300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>471.511800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>436.124500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>416.257000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>433.416100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>409.977000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>428.246500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>387.730300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>391.496100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>371.923600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>386.817900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>419.494900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>349.571400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>378.399600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>383.854600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>351.387700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>357.465100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>362.356800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>359.925700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>349.596700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>345.730400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>395.290200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 3 (data size: 1029)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='258' max='258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [258/258 00:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>508.817400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>525.396700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>465.678400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>472.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>482.954100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>442.700300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>488.351100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>419.909200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>441.477000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>418.105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>439.788800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>411.742500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>367.348200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>404.518900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>400.317100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>372.802300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>373.405200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>364.966400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>371.027200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>355.876000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>381.347200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>386.086200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>379.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>367.488000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>376.897400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 4 (data size: 578)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [146/146 00:24, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>531.396300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>501.929600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>475.653700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>474.633200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>473.800600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>470.062300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>451.732800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>412.667600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>419.804700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>414.272400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>401.032200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>410.767600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>429.318700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>417.106900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 5 (data size: 2309)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='578' max='578' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [578/578 01:35, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>516.053100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>510.789700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>473.522400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>500.498500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>454.537300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>450.724800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>436.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>441.936500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>400.468500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>447.889500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>410.441300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>387.181600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>424.839100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>400.624600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>420.209700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>370.587300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>399.497300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>412.242200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>400.328900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>381.507600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>379.638800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>366.754200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>370.763900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>384.917800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>347.486400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>365.389000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>384.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>350.084300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>355.493200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>318.030700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>315.749100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>328.692100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>342.297100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>329.705400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>354.712700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>334.811100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>332.229100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>337.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>326.124400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>336.606200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>306.577100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>332.651800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>336.727300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>313.376400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>321.434100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>299.025800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>334.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>318.843500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>346.227900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>341.147400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>323.396700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>327.784700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>299.838200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>317.220800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>346.402700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>318.503700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>315.848200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_418300/1516574793.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=0.7776, CER=0.2792, SER=1.0000\n",
      "Round 4\n",
      "Client 1 (data size: 1004)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='252' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [252/252 00:41, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>385.277600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>388.773200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>405.132100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>357.513800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>364.220400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>376.069600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>374.602300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>386.693800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>345.306200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>344.348200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>356.908600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>347.991800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>302.212200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>312.453200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>313.811500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>336.800800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>318.980600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>328.857600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>323.544600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>321.098600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>321.344300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>305.806600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>305.877000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>330.329600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>307.887500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 (data size: 1077)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:44, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>374.189500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>376.085100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>370.279100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>375.210400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>358.402500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>352.935100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>376.737800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>350.639900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>339.302400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>357.508400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>338.054900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>354.639800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>324.474200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>324.377800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>306.676800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>315.461200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>346.098800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>289.961500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>316.219300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>317.860300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>292.833600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>298.872200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>304.030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>303.898100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>298.274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>291.635400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>331.678900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 3 (data size: 1029)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='258' max='258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [258/258 00:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>377.506800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>398.666700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>351.996700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>367.651900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>380.587900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>354.183300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>394.755500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>342.716800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>359.673800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>346.791200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>367.093000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>342.328600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>305.587800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>331.354700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>331.374800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>307.937300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>308.751700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>301.124400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>309.115200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>296.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>318.116100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>324.325100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>319.099400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>309.311100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>314.572000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 4 (data size: 578)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [146/146 00:24, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>394.759400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>382.036300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>367.782300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>372.394700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>375.486200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>373.174600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>362.272500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>329.188200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>330.940100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>330.608000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>320.548900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>327.171500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>345.289900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>335.131600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 5 (data size: 2309)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='578' max='578' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [578/578 01:35, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>382.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>391.797300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>365.545700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>393.503600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>355.824500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>358.448500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>349.858900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>358.760100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>325.439600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>371.974500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>341.309100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>321.853100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>356.211300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>335.690900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>357.476700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>310.221300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>340.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>355.586000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>346.429100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>328.642100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>328.799800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>317.344500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>321.298600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>335.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>300.372700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>318.968900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>339.765200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>306.352100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>312.897800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>272.740300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>272.617600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>286.581900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>297.182400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>286.448000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>308.103300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>292.634100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>289.674900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>295.290200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>285.654600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>297.352100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>268.071500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>291.997200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>296.161000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>276.161600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>282.586500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>264.981800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>295.842500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>282.810300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>306.305600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>303.173800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>285.732100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>291.638600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>265.353400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>280.103400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>308.946700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>284.033900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>281.874600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_418300/1516574793.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=0.7142, CER=0.2450, SER=1.0000\n",
      "Round 5\n",
      "Client 1 (data size: 1004)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='252' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [252/252 00:41, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>321.117200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>334.974200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>350.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>309.912500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>314.870700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>330.945800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>330.647000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>343.233100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>304.155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>303.670200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>315.916000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>309.922800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>267.292000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>272.919600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>275.199400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>298.164900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>279.974900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>290.032500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>286.849000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>284.820500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>284.827300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>270.011100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>271.595200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>296.686000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>275.400300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 (data size: 1077)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:44, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>311.574600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>323.208400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>318.172200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>325.022600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>311.841300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>307.875100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>330.819400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>306.604700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>298.254200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>315.389700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>299.021200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>315.011700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>288.235100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>287.362700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>267.941500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>275.310400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>303.948300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>255.193800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>279.567200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>280.812000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>259.143400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>264.710300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>269.707800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>270.496700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>267.101900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>260.775300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>295.957900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 3 (data size: 1029)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='258' max='258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [258/258 00:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>317.428800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>339.747100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>300.741100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>316.835800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>329.893700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>308.722400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>344.841900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>301.549500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>316.216900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>307.514700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>327.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>304.512000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>270.689400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>288.240900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>292.440700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>269.376700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>271.734400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>265.156900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>273.668000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>261.107500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>281.212400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>287.632100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>283.692800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>274.249100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>278.647000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 4 (data size: 578)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [146/146 00:24, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>332.598700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>326.662800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>316.787300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>320.868900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>326.600400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>324.392100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>316.803900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>284.249800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>283.985100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>286.085000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>277.068200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>283.839600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>300.254100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>292.178700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 5 (data size: 2309)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='578' max='578' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [578/578 01:35, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>321.217200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>338.238900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>316.686300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>340.239500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>306.462200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>311.011600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>305.471800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>313.221500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>286.652300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>328.858900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>301.714900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>285.700500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>317.738300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>297.599100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>319.420500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>274.387400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>303.677900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>321.245300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>313.401500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>297.522100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>297.847900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>286.435000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>290.111800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>305.721500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>271.610300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>289.400100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>310.618400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>278.843500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>285.222000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>243.613300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>244.606000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>258.727100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>268.001400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>257.579100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>277.345900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>264.134200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>261.953300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>266.866900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>258.842000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>271.638100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>242.194200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>265.394100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>268.885100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>251.460600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>256.219900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>242.397800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>269.719800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>258.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>279.867000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>276.903800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>260.976000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>267.398700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>242.356100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>254.951900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>283.487700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>261.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>258.855100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_418300/1516574793.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=0.6736, CER=0.2258, SER=1.0000\n",
      "Round 6\n",
      "Client 1 (data size: 1004)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='252' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [252/252 00:41, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>279.819200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>301.272900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>314.786500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>278.302100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>283.464300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>301.106900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>301.987200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>314.533200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>275.967200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>276.831200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>288.509100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>283.853100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>243.023900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>244.978100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>248.435900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>271.052400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>253.018100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>263.628200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>261.545700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>259.925800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>259.720200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>245.594600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>247.819200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>273.062700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>252.986600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 (data size: 1077)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:44, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>271.330200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>290.076100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>284.856100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>293.835300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>279.580600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>278.118700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>299.653100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>276.660600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>270.399500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>286.163300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>272.860100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>288.906300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>262.885500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>261.508800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>240.959900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>246.917700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>274.363900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>230.594600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>253.561500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>255.098600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>236.106800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>240.367000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>246.051700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>247.733600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>244.590800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>239.324500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>271.904800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 3 (data size: 1029)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='258' max='258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [258/258 00:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>278.994800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>303.034000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>268.951700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>285.564000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>298.583100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>278.568200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>312.130200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>272.486900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>287.258600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>281.365100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>300.591700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>278.757000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>247.701100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>258.796000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>265.066300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>243.351500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>246.114200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>240.552600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>248.950600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>237.636300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>255.548100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>262.039700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>259.211300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>250.742500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>254.563000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 4 (data size: 578)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [146/146 00:24, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>291.813700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>290.854200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>283.965600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>287.654100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>295.339700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>294.631700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>288.647500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>255.051100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>252.973800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>257.058800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>248.567800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>255.279200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>271.238100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>264.607700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 5 (data size: 2309)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='578' max='578' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [578/578 01:35, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>280.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>304.398400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>284.759800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>307.246300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>274.973200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>279.199100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>275.212600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>282.209400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>260.419900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>298.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>274.384300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>260.239800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>291.197900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>270.162400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>291.576000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>249.017700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>277.805300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>296.191400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>289.481600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>274.630900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>275.343800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>263.737300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>267.252100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>283.138000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>250.910900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>267.720900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>288.809100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>259.263200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>264.926400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>221.887100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>223.919200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>237.739900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>245.968600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>235.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>254.853100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>242.802200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>240.695900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>245.950800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>238.532100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>252.320500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>223.179500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>245.945800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>249.125200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>232.861300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>236.749100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>225.185200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>250.242700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>239.645800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>260.100600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>257.063900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>242.529700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>249.346900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>225.142800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>236.826300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>264.547800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>243.259500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>242.263500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_418300/1516574793.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=0.6454, CER=0.2129, SER=1.0000\n",
      "Round 7\n",
      "Client 1 (data size: 1004)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='252' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [252/252 00:41, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>249.180600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>276.882800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>287.907700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>254.514200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>260.457500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>278.792200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>280.163500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>292.475200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>254.738100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>256.395200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>267.454900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>263.722900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>224.716600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>223.552500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>228.375400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>249.250800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>232.878500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>242.892400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>241.394100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>240.295100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>240.595200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>226.725600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>229.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>255.421000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>235.998300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 (data size: 1077)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:44, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>240.847200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>265.021900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>259.883000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>269.336400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>255.923600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>255.172200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>274.788600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>254.018300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>248.496500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>263.618900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>253.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>269.164600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>243.327800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>241.164500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>219.927600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>225.372900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>251.420400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>211.953800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>233.079300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>235.184500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>217.896700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>221.390200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>227.432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>230.115500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>226.937600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>222.872800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>253.598200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 3 (data size: 1029)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='258' max='258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [258/258 00:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>248.021800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>275.162100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>245.220600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>261.756100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>274.379300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>255.715300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>287.109300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>250.853600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>265.244700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>261.699700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>279.734300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>258.873500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>230.314100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>236.334700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>243.515900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>223.410700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>226.631000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>221.556300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>229.816000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>218.987600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>235.766300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>242.671800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>239.899400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>232.858300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>235.228100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 4 (data size: 578)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [146/146 00:24, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>260.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>264.442100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>259.869800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>262.762900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>272.119700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>272.929800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>268.202200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>232.991400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>230.232900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>235.196900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>227.099300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>233.607500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>249.824300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>244.455200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 5 (data size: 2309)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='578' max='578' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [578/578 01:35, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>248.599300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>278.860800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>259.928200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>282.114200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>251.635600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>255.307400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>252.274700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>258.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>240.279600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>274.836900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>252.806800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>240.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>269.803500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>248.384100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>269.422200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>229.336500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>257.070600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>276.155300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>270.028300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>256.091400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>257.974400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>245.344800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>248.764400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>264.812000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>234.315200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>250.079000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>271.193000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>243.511800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>248.234000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>203.514100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>207.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>220.878300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>227.764800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>217.184900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>236.427600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>225.677900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>223.309500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>228.918600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>221.667400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>236.305700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>208.030100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>229.733400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>232.931700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>217.907000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>220.957800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>211.090200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>234.008200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>224.238000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>243.792300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>240.949400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>227.087500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>234.385200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>211.090400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>222.152500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>248.812000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>228.694600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>228.470900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_418300/1516574793.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=0.6219, CER=0.2034, SER=1.0000\n",
      "Round 8\n",
      "Client 1 (data size: 1004)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='252' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [252/252 00:41, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>223.820500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>257.553500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>265.516400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>234.779200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>241.174700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>259.989200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>261.132800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>274.300600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>236.970600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>239.663800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>250.332300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>247.171400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>209.951100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>206.098700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>211.600300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>231.151200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>216.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>226.380700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>224.945800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>224.619100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>224.867300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>211.600700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>215.574000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>241.648900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>222.508000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 (data size: 1077)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:44, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>215.046900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>244.452600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>238.879200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>249.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>236.331800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>236.434000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>254.432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>235.835800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>230.796000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>245.048400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>236.577900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>252.796500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>227.340800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>224.423500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>202.759100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>207.513200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>232.883900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>196.665600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>216.645100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>219.164400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>202.952900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>206.329100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>212.588400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>216.013700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>212.637700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>209.968000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>238.943700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 3 (data size: 1029)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='258' max='258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [258/258 00:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>221.737900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>253.056300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>225.506600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>242.161200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>254.711600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>237.084200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>266.929000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>233.202200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>246.906300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>245.583100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>262.814700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>242.663200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>216.386800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>218.011400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>226.266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>207.598900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>210.619800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>206.169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>214.151500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>203.510400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>219.826700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>227.186400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>224.178500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>218.462900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>219.951000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 4 (data size: 578)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [146/146 00:24, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>233.636600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>243.009900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>240.026900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>243.348800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>253.019600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>255.483200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>251.492900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>215.138300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>211.661100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>217.690400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>209.874300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>216.129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>232.766200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>228.590000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 5 (data size: 2309)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='578' max='578' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [578/578 01:35, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>222.200500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>257.134000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>239.318800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>260.905900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>233.238300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>235.296400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>233.757400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>239.058100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>223.128900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>255.094700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>234.924500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>222.603000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>252.154000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>230.322100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>251.327300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>213.236500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>240.035900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>258.913900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>253.503200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>240.719500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>243.382200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>230.297200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>233.838100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>249.462800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>220.303800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>235.267400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>256.368900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>230.252800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>233.938800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>187.450300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>192.005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>205.906500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>212.357700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>202.276200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>221.211200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>211.401600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>208.674300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>214.851300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>207.649200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>222.754300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>195.676000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>216.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>219.163400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>205.149600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>207.677000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>199.264900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>220.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>210.909100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>230.025700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>227.713000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>213.827600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>222.036300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>199.523600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>209.914900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>235.104100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>216.771900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>216.844400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_418300/1516574793.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=0.6031, CER=0.1955, SER=1.0000\n",
      "Round 9\n",
      "Client 1 (data size: 1004)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='252' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [252/252 00:41, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>201.859100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>240.526600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>246.476600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>218.268900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>224.639200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>244.114500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>244.814400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>258.596800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>221.620300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>225.632700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>235.878300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>232.961100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>197.459800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>191.196100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>197.392000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>215.927900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>201.741000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>212.442300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>211.288100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>211.618100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>211.382600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>199.080400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>203.706300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>230.160500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>211.417900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 (data size: 1077)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:44, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>192.411400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>226.633000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>220.972500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>232.235000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>219.360700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>220.487900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>237.902300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>220.232800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>216.337100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>229.206000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>223.182400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>238.832100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>214.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>210.611500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>188.550700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>192.594300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>216.871500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>183.646400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>202.985800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>206.141500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>190.520600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>194.167200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>200.123100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>204.491700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>201.066700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>199.364400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>227.253800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 3 (data size: 1029)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='258' max='258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [258/258 00:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>198.627200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>234.033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>208.752800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>225.707900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>237.861600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>221.335300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>249.958100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>218.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>231.221700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>231.377200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>248.412500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>228.724500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>204.406500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>202.478400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>211.665900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>193.966700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>196.903900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>193.332500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>201.114100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>190.753700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>206.552500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>214.501100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>211.333800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>206.465500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>207.664600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 4 (data size: 578)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [146/146 00:24, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>210.430400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>224.585000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>223.399200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>227.204400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>236.978400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>240.414400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>237.341800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>199.921600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>195.970400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>202.916800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>195.640700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>201.927100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>218.903000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>215.906600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 5 (data size: 2309)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='578' max='578' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [578/578 01:35, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>199.051100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>238.759700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>222.169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>243.271300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>216.993600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>217.564600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>216.922000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>222.344800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>208.173200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>237.992200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>219.912800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>207.033100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>236.401100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>214.253100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>235.576300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>199.519400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>225.209000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>244.087400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>239.035700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>227.426400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>230.571500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>216.996800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>221.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>236.147800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>208.010800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>222.587100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>243.358200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>218.632900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>221.754100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>174.037100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>178.875500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>192.689700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>198.099400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>188.963600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>207.715100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>198.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>195.324400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>202.615400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>195.210900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>211.259500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>185.047800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>204.989300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>206.977700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>194.073200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>196.593000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>189.134600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>208.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>199.798500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>218.473600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>216.420200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>203.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>211.727100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>189.894000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>199.781000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>223.821000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>206.932700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>207.191300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_418300/1516574793.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=0.5872, CER=0.1892, SER=1.0000\n",
      "Round 10\n",
      "Client 1 (data size: 1004)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='252' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [252/252 00:41, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>182.247600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>224.767400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>229.564300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>203.219000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>210.254700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>229.923000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>230.775100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>244.945100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>208.325100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>213.883500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>223.256100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>220.403600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>186.615900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>178.252100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>185.082400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>202.415600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>189.669700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>200.652600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>199.466300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>200.461900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>200.024300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>188.393100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>194.026500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>220.490900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>202.153700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 2 (data size: 1077)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:44, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>172.282500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>211.221500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>205.464700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>217.390300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>204.261400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>206.472900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>223.223100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>206.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>204.241100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>215.269600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>211.967300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>226.644000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>202.703600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>198.619600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>176.331200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>179.972500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>202.826200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>172.192700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>190.900400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>194.434100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>179.686300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>183.751300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>189.162000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>194.344500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>191.624800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>190.419100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>217.113400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 3 (data size: 1029)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='258' max='258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [258/258 00:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>178.138100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>217.083100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>193.938800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>211.262700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>222.759200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>207.498900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>235.032500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>204.398600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>218.178600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>219.151400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>235.998500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>216.783900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>194.179800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>188.938600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>198.741300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>181.987000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>184.998200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>182.258800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>189.673500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>179.848800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>195.440400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>203.692700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>200.670200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>196.431000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>197.263700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 4 (data size: 578)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='146' max='146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [146/146 00:23, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>189.423000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>208.166900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>209.348100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>212.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>223.129700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>227.213100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>225.102800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>186.464000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>182.448900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>190.632700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>183.963100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>190.309800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>207.091600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>205.282900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 5 (data size: 2309)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418300/223340307.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='578' max='578' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [578/578 01:35, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>178.230800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>222.671200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>206.098100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>226.515300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>202.520800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>202.069700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>201.789400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>207.813600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>195.059800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>222.342800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>206.607000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>193.087300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>222.467900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>200.197900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>222.213500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>187.617100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>212.076800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>231.038400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>226.296100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>215.566200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>219.258900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>205.078900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>209.852500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>224.448800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>196.910100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>211.732400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>231.578800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>208.702900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>211.086500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>162.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>167.546200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>181.295400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>185.940800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>177.174500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>195.568800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>188.063100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>183.604400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>191.839700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>184.267000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>200.796200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>175.654500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>195.079000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>196.505900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>184.007600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>186.653600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>180.560200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>197.454500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>189.992800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>208.210300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>206.615500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>193.412600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>202.755900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>181.452500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>191.314100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>214.007300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>198.542100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>198.823800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_418300/1516574793.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='179' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/179 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after round: WER=0.5760, CER=0.1842, SER=1.0000\n"
     ]
    }
   ],
   "source": [
    "global_model = deepcopy(base_model)\n",
    "round_metrics = []\n",
    "\n",
    "for round_num in range(10):\n",
    "    print(f\"Round {round_num + 1}\")\n",
    "    selected_clients = random.sample(client_datasets, k=5)\n",
    "    weights = []\n",
    "    client_losses = []\n",
    "\n",
    "    for i, client_data in enumerate(selected_clients):\n",
    "        print(f\"Client {i+1} (data size: {len(client_data)})\")\n",
    "        local_model = copy.deepcopy(global_model)\n",
    "        state, train_metrics = local_finetune(\n",
    "            local_model,\n",
    "            client_data,\n",
    "            processor,\n",
    "            data_collator,\n",
    "            compute_metrics,\n",
    "            f\"./client{i}_round{round_num}\"\n",
    "        )\n",
    "        weights.append(state)\n",
    "        client_losses.append(train_metrics[\"train_loss\"])\n",
    "\n",
    "    # FedAvg\n",
    "    avg_weights = fed_avg(weights)\n",
    "    global_model.load_state_dict(avg_weights)\n",
    "\n",
    "    # Evaluate global model for each iteration\n",
    "    eval_metrics = evaluate_global_model(global_model, eval_dataset)\n",
    "    round_metrics.append({\n",
    "        \"round\": round_num + 1,\n",
    "        \"train_loss\": sum(client_losses) / len(client_losses),\n",
    "        \"eval_loss\": eval_metrics.get(\"eval_loss\"),\n",
    "        \"eval_wer\": eval_metrics.get(\"eval_wer\"),\n",
    "        \"eval_cer\": eval_metrics.get(\"eval_cer\"),\n",
    "        \"eval_ser\": eval_metrics.get(\"eval_ser\"),\n",
    "    })\n",
    "\n",
    "    global_model.save_pretrained(f\"./FedAvg_checkpoints/round{round_num+1}_global_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90805744-20df-406a-9e41-a9c4480df27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_model.save_pretrained(\"./FedAvg_checkpoints/federated_distilhubert_asr\")\n",
    "processor.save_pretrained(\"./FedAvg_checkpoints/federated_distilhubert_asr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8257749b-1636-4b2f-a8a4-4e6d8e7113b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = pd.DataFrame(round_metrics)\n",
    "metric_df.to_csv(\"./FedAvg_checkpoints/FedAvg_round_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f359e39d-c1f2-4fc3-bec2-74eac7fb8876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(metric_df[\"round\"], metric_df[\"eval_wer\"], label=\"WER\")\n",
    "plt.plot(metric_df[\"round\"], metric_df[\"eval_cer\"], label=\"CER\")\n",
    "plt.plot(metric_df[\"round\"], metric_df[\"eval_ser\"], label=\"SER\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.title(\"Evaluation Metrics per Round\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa7a3e5-5826-4283-b6ae-8a217c721f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
