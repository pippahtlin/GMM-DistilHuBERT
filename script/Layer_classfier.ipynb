{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a23a7a8-694e-4148-938a-d6c3ecb49f09",
   "metadata": {},
   "source": [
    "We use PWCCA to find the most representative layer for the finetuned DistilHuBERT \\\n",
    "https://github.com/ankitapasad/layerwise-analysis \\\n",
    "MFA env: mfa_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c3310f9-3f46-46a7-83a1-5faecbf6d7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_gpu_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0dd7cbd-32ed-4fa6-be52-f9de5731aa70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import HubertForCTC, AutoProcessor\n",
    "from DHuBERT_utils import *\n",
    "from datasets import load_from_disk\n",
    "import soundfile as sf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b7c9e77-6e0a-4268-a468-e00993423ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of layers (incl. input): 3\n",
      "Shape of one layer: torch.Size([1, 49, 768])\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = HubertForCTC.from_pretrained(\"/scratch/pippalin2/jupyter/GMM-DistilHuBERT/checkpoints_distilhubert_asr/final_model\").to('cuda')\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"/scratch/pippalin2/jupyter/GMM-DistilHuBERT/checkpoints_distilhubert_asr/final_model\")\n",
    "\n",
    "# Dummy input\n",
    "waveform = torch.randn(1, 16000).to('cuda')\n",
    "\n",
    "\n",
    "# Forward pass with hidden states\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_values=waveform, output_hidden_states=True)\n",
    "\n",
    "# Hidden states: list of tensors from each layer + input embeddings\n",
    "hidden_states = outputs.hidden_states  # List of (batch_size, time_steps, hidden_dim)\n",
    "\n",
    "print(f\"# of layers (incl. input): {len(hidden_states)}\")\n",
    "print(f\"Shape of one layer: {hidden_states[1].shape}\")  # skip index 0 if you want encoder layers only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8080d2e8-41a9-4ed7-a32b-1d361bdeaeff",
   "metadata": {},
   "source": [
    "Distil HuBERT has 7 CNN layer and 3 transformer layer. We apply PWCCA on the transformer layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a5f891-6762-4c1f-b9b6-1f684c37b5d0",
   "metadata": {},
   "source": [
    "### 1. Extract Hidden Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfb415cc-80bb-494d-bfd5-71e9c354f120",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = data.select(range(500))  # Select first 500 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bfd6b00-d6d3-4a32-ab92-78e4b477270e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function extract_layer_representations.<locals>.get_features_batch at 0x7f7cd1d8dcf0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0942f92650254912bd7dea03183d5131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting layer 0 representations:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'phone_segments'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m layer_reps \u001b[38;5;241m=\u001b[39m extract_layer_representations(model, processor, small_data, layer)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# CCA-phone\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m phone_pooled \u001b[38;5;241m=\u001b[39m [pool_segment_features(x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer_output\u001b[39m\u001b[38;5;124m\"\u001b[39m], x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphone_segments\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m layer_reps]\n\u001b[1;32m      9\u001b[0m phone_flat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(phone_pooled)\n\u001b[1;32m     10\u001b[0m phone_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphone_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m layer_reps])\n",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m layer_reps \u001b[38;5;241m=\u001b[39m extract_layer_representations(model, processor, small_data, layer)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# CCA-phone\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m phone_pooled \u001b[38;5;241m=\u001b[39m [pool_segment_features(x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer_output\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mphone_segments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m layer_reps]\n\u001b[1;32m      9\u001b[0m phone_flat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(phone_pooled)\n\u001b[1;32m     10\u001b[0m phone_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphone_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m layer_reps])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'phone_segments'"
     ]
    }
   ],
   "source": [
    "cca_phone_scores = []\n",
    "cca_word_scores = []\n",
    "\n",
    "for layer in range(3):\n",
    "    layer_reps = extract_layer_representations(model, processor, small_data, layer)\n",
    "\n",
    "    # CCA-phone\n",
    "    phone_pooled = [pool_segment_features(x[\"layer_output\"], x[\"phone_segments\"]) for x in layer_reps]\n",
    "    phone_flat = np.concatenate(phone_pooled)\n",
    "    phone_labels = np.concatenate([x[\"phone_labels\"] for x in layer_reps])\n",
    "    phone_onehot = prepare_onehot_labels(phone_labels)\n",
    "    cca_phone_scores.append(compute_pwcca_similarity(phone_flat, phone_onehot))\n",
    "\n",
    "    # CCA-word\n",
    "    word_pooled = [pool_segment_features(x[\"layer_output\"], x[\"word_segments\"]) for x in layer_reps]\n",
    "    word_flat = np.concatenate(word_pooled)\n",
    "    word_labels = np.concatenate([x[\"word_labels\"] for x in layer_reps])\n",
    "    word_onehot = prepare_onehot_labels(word_labels)\n",
    "    cca_word_scores.append(compute_pwcca_similarity(word_flat, word_onehot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a964a13f-43a4-4f91-9b35-a2c8cf5c8fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(4), cca_phone_scores, label='CCA-phone')\n",
    "plt.plot(range(4), cca_word_scores, label='CCA-word')\n",
    "plt.xlabel(\"Layer\")\n",
    "plt.ylabel(\"PWCCA Similarity\")\n",
    "plt.legend()\n",
    "plt.title(\"Layer-wise PWCCA Scores (DistilHuBERT)\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
