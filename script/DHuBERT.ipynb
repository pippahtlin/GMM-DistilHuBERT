{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d664494-3b0a-47bc-9b03-183e8f9e75e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoFeatureExtractor, AutoModel\n",
    "import torch\n",
    "import torchaudio\n",
    "from datasets import Dataset, load_from_disk\n",
    "import numpy as np\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b9257ca-6dac-4e68-9288-67e519073744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a56b4f0ce944cb9be4211cdfaa79794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import dataset\n",
    "dataset = load_from_disk(\"/share/data/lang/users/ttic_31110/GMM_DHuBERT/GMM-DistilHuBERT/data/hf_librispeech_clean100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aa6464-5048-4b04-ad6a-2a7adcef3b2b",
   "metadata": {},
   "source": [
    "### Test DHuBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1e7266f-2027-4d77-af0d-d396c91b036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = dataset[0]\n",
    "waveform = torch.tensor(example[\"audio\"][\"array\"])\n",
    "sampling_rate = example[\"audio\"][\"sampling_rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2de20974-9c8b-4fff-b0ea-ce48b6ea0b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden state shape: torch.Size([1, 704, 768])\n"
     ]
    }
   ],
   "source": [
    "# Load the feature extractor and model\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"ntu-spml/distilhubert\")\n",
    "model = AutoModel.from_pretrained(\"ntu-spml/distilhubert\").to(device)\n",
    "\n",
    "# Preprocess waveform\n",
    "inputs = feature_extractor(waveform, sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Output hidden state shape\n",
    "print(\"Hidden state shape:\", outputs.last_hidden_state.shape)\n",
    "# 704 tokens (acoustic representation), each a 768-d vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0831e54-79bb-486d-a6d7-7c4e1975a6f4",
   "metadata": {},
   "source": [
    "### Try Fine-Tuning on ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9a35e54-a764-4327-a6de-e789d9d34970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForCTC, TrainingArguments, Trainer, Wav2Vec2Processor, EarlyStoppingCallback\n",
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Union\n",
    "import jiwer\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc00e02c-2ee6-409a-bde8-f8ce4aae76b0",
   "metadata": {},
   "source": [
    "\n",
    "#### processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "\n",
    "* Apply the processor that wraps a feature extractor and tokenizer to the waveform.\n",
    "* Returns a dict with a key like `input_values`: padded and normalized audio ready for the model.\n",
    "* You extract the first (and only) item in the batch using [0].\n",
    "\n",
    "`example[\"input_values\"]`: a vector of floats the model will ingest.\n",
    "\n",
    "#### with processor.as_target_processor():\n",
    "\n",
    "* Switches the processor into target mode which changes its behavior to tokenize text, not audio.\n",
    "* This is important for models where the same processor handles both input and label preprocessing.\n",
    "\n",
    "#### example[\"labels\"] = processor(example[\"text\"]).input_ids\n",
    "\n",
    "* Tokenizes the reference transcript into a sequence of IDs aka label tokens.\n",
    "* They’ll be aligned to the model’s output using CTC loss, allowing flexible alignment between audio and text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34cbb8e5-b868-433c-9b8b-a75264de4cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of HubertForCTC were not initialized from the model checkpoint at ntu-spml/distilhubert and are newly initialized: ['lm_head.bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b355d70dd37b4752858e5fb28c3d7b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# processor = Wav2Vec2Processor.from_pretrained(\"facebook/hubert-large-ls960-ft\") #HuBERT's processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"/scratch/pippalin2/jupyter/GMM-DistilHuBERT/processor\") # load pretrained\n",
    "model = AutoModelForCTC.from_pretrained(\"ntu-spml/distilhubert\").to(\"cuda\")\n",
    "\n",
    "def prepare(example):\n",
    "    audio = example[\"audio\"]\n",
    "    example[\"input_values\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "    with processor.as_target_processor():\n",
    "        example[\"labels\"] = processor(example[\"text\"]).input_ids\n",
    "    return example\n",
    "\n",
    "# data = dataset.map(prepare, remove_columns=dataset.column_names)\n",
    "# data.save_to_disk(\"/scratch/pippalin2/jupyter/GMM-DistilHuBERT/processed_dataset\")\n",
    "data = load_from_disk(\"/scratch/pippalin2/jupyter/GMM-DistilHuBERT/processed_dataset\")\n",
    "dataset = data.train_test_split(test_size=0.1)\n",
    "train_dataset = dataset[\"train\"]\n",
    "eval_dataset = dataset[\"test\"]\n",
    "\n",
    "# Format into tensor\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_values\", \"labels\"])\n",
    "eval_dataset.set_format(type=\"torch\", columns=[\"input_values\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "031ec126-4959-44d8-bc52-07944db82368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25670 2853\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(eval_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b24c87-682c-46f4-8c6b-2327c8da0029",
   "metadata": {},
   "source": [
    "#### data collator: \n",
    "Pad and Convert lists of samples into batched tensors for the model, handle labels appropriately for the loss function (CTC)\n",
    "\n",
    "* `padding`: Can be `True`, `\"longest\"`, or `\"max_length\"` – determines how padding is applied.\n",
    "\n",
    "def __call__(self, features: List[Dict]) -> Dict[str, torch.Tensor]:\n",
    "* `features`:{\"input_values\": tensor, \"labels\": [int, int, ...]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "130bc12a-361c-412e-9c02-bbe3fdc77beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Union\n",
    "import torch\n",
    "\n",
    "class DataCollatorCTCWithPadding:\n",
    "    def __init__(self, processor, padding: Union[bool, str] = True):\n",
    "        self.processor = processor\n",
    "        self.padding = padding\n",
    "\n",
    "    def __call__(self, features: List[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_features = [{\"input_values\": f[\"input_values\"]} for f in features]\n",
    "        label_features = [{\"input_ids\": f[\"labels\"]} for f in features]\n",
    "\n",
    "        # Padding\n",
    "        batch = self.processor.feature_extractor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        labels_batch = self.processor.tokenizer.pad(\n",
    "            label_features,\n",
    "            padding=self.padding,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Replace padding token IDs with -100 for CTC loss to ignore\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(\n",
    "            labels_batch.attention_mask.ne(1), -100\n",
    "        )\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2b29a882-17bc-410f-a2f7-9a23e3f24240",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/scratch/pippalin2/jupyter/GMM-DistilHuBERT/checkpoints_distilhubert_asr\",\n",
    "    per_device_train_batch_size=4,\n",
    "    eval_strategy=\"steps\", \n",
    "    eval_steps=800, # evaluate every 1000 steps\n",
    "    logging_steps=200,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=800,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\", \n",
    "    greater_is_better=False, # smaller WER is better\n",
    "    fp16=True,\n",
    "    resume_from_checkpoint=False,  # we handle this manually\n",
    "    report_to=\"wandb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5792f136-0a13-4a83-983a-8b2823cd07cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStoppingCallback(\n",
    "    early_stopping_patience=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0d02b75-7b86-424e-995c-cc3badad357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = jiwer.Compose([\n",
    "    jiwer.ToLowerCase(),\n",
    "    jiwer.RemovePunctuation(),\n",
    "    jiwer.RemoveMultipleSpaces(),\n",
    "    jiwer.Strip(),\n",
    "])\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = torch.argmax(torch.tensor(pred_logits), dim=-1)\n",
    "\n",
    "    # Decode predictions\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "\n",
    "    # Decode references\n",
    "    label_ids = pred.label_ids\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    label_str = processor.batch_decode(label_ids, group_tokens=False)\n",
    "\n",
    "    # Normalize\n",
    "    pred_str = [transform(p) for p in pred_str]\n",
    "    label_str = [transform(l) for l in label_str]\n",
    "\n",
    "    # Compute metrics\n",
    "    wer = jiwer.wer(label_str, pred_str)\n",
    "    cer = jiwer.cer(label_str, pred_str)\n",
    "\n",
    "    # Sentence Error Rate: fraction of sentences with at least 1 error\n",
    "    ser = sum(p != l for p, l in zip(pred_str, label_str)) / len(label_str)\n",
    "\n",
    "    return {\n",
    "        \"wer\": wer,\n",
    "        \"cer\": cer,\n",
    "        \"ser\": ser,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f4888d57-87be-4d53-800e-0490092aec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8129cee8-a50b-4535-9a0d-c0e47239e3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121574/1390310763.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4815' max='4815' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4815/4815 26:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "      <th>Cer</th>\n",
       "      <th>Ser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>798.918300</td>\n",
       "      <td>1396.765503</td>\n",
       "      <td>0.770945</td>\n",
       "      <td>0.269298</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>590.617400</td>\n",
       "      <td>1082.323120</td>\n",
       "      <td>0.649390</td>\n",
       "      <td>0.213331</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>520.117300</td>\n",
       "      <td>956.906250</td>\n",
       "      <td>0.598035</td>\n",
       "      <td>0.193059</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>486.007200</td>\n",
       "      <td>894.532043</td>\n",
       "      <td>0.568643</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>457.719700</td>\n",
       "      <td>859.376709</td>\n",
       "      <td>0.552496</td>\n",
       "      <td>0.174181</td>\n",
       "      <td>0.999649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>453.721800</td>\n",
       "      <td>848.710571</td>\n",
       "      <td>0.547858</td>\n",
       "      <td>0.172089</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/share/data/lang/users/ttic_31110/GMM_DHuBERT/mc3/envs/gmm-hubert/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4815, training_loss=675.2554385303089, metrics={'train_runtime': 1562.9262, 'train_samples_per_second': 49.273, 'train_steps_per_second': 3.081, 'total_flos': 2.816043967793157e+18, 'train_loss': 675.2554385303089, 'epoch': 3.0})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=processor,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "checkpoint_path = \"/scratch/pippalin2/jupyter/GMM-DistilHuBERT/checkpoints_distilhubert_asr\"\n",
    "last_checkpoint = None\n",
    "if os.path.isdir(checkpoint_path) and os.listdir(checkpoint_path):\n",
    "    last_checkpoint = checkpoint_path\n",
    "\n",
    "trainer.train(resume_from_checkpoint=last_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3886b130-32d4-4041-bd83-b0acfc60ebeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "trainer.save_model(\"/scratch/pippalin2/jupyter/GMM-DistilHuBERT/checkpoints_distilhubert_asr/final_model\")\n",
    "\n",
    "# Save the processor (feature extractor + tokenizer)\n",
    "processor.save_pretrained(\"/scratch/pippalin2/jupyter/GMM-DistilHuBERT/checkpoints_distilhubert_asr/final_model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
