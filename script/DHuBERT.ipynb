{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d664494-3b0a-47bc-9b03-183e8f9e75e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoFeatureExtractor, AutoModel\n",
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "import torchaudio\n",
    "\n",
    "# Load the feature extractor and model\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"ntu-spml/distilhubert\")\n",
    "model = AutoModel.from_pretrained(\"ntu-spml/distilhubert\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b9257ca-6dac-4e68-9288-67e519073744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: CHAPTER ONE MISSUS RACHEL LYNDE IS SURPRISED MISSUS RACHEL LYNDE LIVED JUST WHERE THE AVONLEA MAIN ROAD DIPPED DOWN INTO A LITTLE HOLLOW FRINGED WITH ALDERS AND LADIES EARDROPS AND TRAVERSED BY A BROOK\n"
     ]
    }
   ],
   "source": [
    "# import dataset\n",
    "training_dataset = torchaudio.datasets.LIBRISPEECH(\n",
    "    root=\"/scratch/pippalin2/jupyter/GMM-DistilHuBERT/data\",    # where your LibriSpeech folder lives\n",
    "    url=\"train-clean-100\",       # this must match the subfolder name\n",
    "    download=False            \n",
    ")\n",
    "waveform, sample_rate, transcript, _, _, _ = training_dataset[0]\n",
    "print(\"Transcript:\", transcript)\n",
    "\n",
    "# Resample if needed: DHuBERT requires 16kHz\n",
    "if sample_rate != 16000:\n",
    "    resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "    waveform = resampler(waveform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aa6464-5048-4b04-ad6a-2a7adcef3b2b",
   "metadata": {},
   "source": [
    "### Test DHuBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2de20974-9c8b-4fff-b0ea-ce48b6ea0b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden state shape: torch.Size([1, 704, 768])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "inputs = feature_extractor(waveform.squeeze(), sampling_rate=16000, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "'''\n",
    "{\n",
    "  'input_values': tensor of shape [1, num_samples]\n",
    "}\n",
    "'''\n",
    "# Run inference\n",
    "with torch.no_grad(): # no need gradient since we are just testing\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Output hidden state shape\n",
    "print(\"Hidden state shape:\", outputs.last_hidden_state.shape)\n",
    "# 704 tokens (acoustic representation), each a 768-d vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0831e54-79bb-486d-a6d7-7c4e1975a6f4",
   "metadata": {},
   "source": [
    "### Try Fine-Tuning on ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b852f7-4d71-469a-bb4b-c8f195692961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load small subset for testing; can change to \"train-clean-100\"\n",
    "librispeech = load_dataset(\"librispeech_asr\", \"clean\", split=\"train.100\")\n",
    "\n",
    "# Show example\n",
    "print(librispeech[0][\"audio\"])\n",
    "print(librispeech[0][\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94071439-1e15-4a03-93c2-2e7d36760385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"ntu-spml/distilhubert\")\n",
    "\n",
    "# Preprocessing function\n",
    "def prepare(example):\n",
    "    audio = example[\"audio\"]\n",
    "\n",
    "    # Extract audio features\n",
    "    example[\"input_values\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "\n",
    "    # Encode labels (character-level)\n",
    "    with processor.as_target_processor():\n",
    "        example[\"labels\"] = processor(example[\"text\"]).input_ids\n",
    "\n",
    "    return example\n",
    "\n",
    "# Apply preprocessing\n",
    "processed_ds = librispeech.map(prepare, remove_columns=librispeech.column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d630e724-f4d0-41de-9eeb-bbc0ec4e15f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import HubertForCTC\n",
    "\n",
    "model = HubertForCTC.from_pretrained(\n",
    "    \"ntu-spml/distilhubert\",\n",
    "    ctc_loss_reduction=\"mean\",\n",
    "    pad_token_id=processor.tokenizer.pad_token_id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b62dfb-49c4-49d1-8408-a2d3893c7014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jiwer\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions.argmax(-1)\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "    wer = jiwer.wer(label_str, pred_str)\n",
    "    return {\"wer\": wer}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7806f8-141d-4acf-b3e9-490cadf1b2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./distilhubert-asr\",\n",
    "    group_by_length=True,\n",
    "    per_device_train_batch_size=8,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=3,\n",
    "    fp16=True,\n",
    "    save_steps=100,\n",
    "    eval_steps=100,\n",
    "    logging_steps=25,\n",
    "    learning_rate=1e-4,\n",
    "    warmup_steps=500,\n",
    "    save_total_limit=2,\n",
    "    gradient_checkpointing=True,\n",
    "    logging_dir=\"./logs\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=processor.feature_extractor.pad,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=processed_ds,\n",
    "    tokenizer=processor\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3063e781-6832-466a-8ee2-bfd7fc767c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load test sample\n",
    "test_ds = load_dataset(\"librispeech_asr\", \"clean\", split=\"test.clean[:1%]\")\n",
    "test_ds = test_ds.map(prepare)\n",
    "\n",
    "# Predict\n",
    "pred = trainer.predict(test_ds)\n",
    "print(\"WER:\", compute_metrics(pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a57977c0-e56c-423a-8b9a-7e04d1e57e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jiwer\n",
      "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting click>=8.1.8 (from jiwer)\n",
      "  Downloading click-8.2.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
      "  Downloading rapidfuzz-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Downloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
      "Downloading click-8.2.0-py3-none-any.whl (102 kB)\n",
      "Downloading rapidfuzz-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Installing collected packages: rapidfuzz, click, jiwer\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [jiwer]32m2/3\u001b[0m [jiwer]\n",
      "Successfully installed click-8.2.0 jiwer-3.1.0 rapidfuzz-3.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defea8c9-024e-407a-84b5-42378629c601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
